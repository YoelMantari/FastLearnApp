
ğŸ§  **Pregunta 1**
Â¿QuÃ© representa un peso (\$w\$) en una neurona artificial?

A. Una variable de salida
B. Un tipo de funciÃ³n de activaciÃ³n
C. La importancia de una entrada
D. Un nÃºmero aleatorio sin efecto

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El peso representa cuÃ¡nto influye una entrada en la salida de la neurona. Durante el entrenamiento, se ajusta para mejorar la predicciÃ³n.

---

ğŸ§  **Pregunta 2**
Â¿CuÃ¡l es la funciÃ³n de una capa oculta en una red neuronal?

A. Recibir datos crudos como entrada
B. Producir directamente la salida final
C. Detectar patrones complejos no evidentes
D. Eliminar entradas redundantes

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Las capas ocultas procesan la informaciÃ³n y ayudan a encontrar patrones que no son lineales ni obvios en los datos.

---

ğŸ§  **Pregunta 3**
Â¿QuÃ© sucede si una red neuronal no tiene capas ocultas?

A. No puede realizar operaciones bÃ¡sicas
B. Se comporta como una regresiÃ³n lineal o logÃ­stica
C. Su salida siempre serÃ¡ 0
D. Se vuelve una red recurrente

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Sin capas ocultas, una red neuronal actÃºa como una regresiÃ³n lineal (o logÃ­stica si tiene funciÃ³n sigmoide).

---

ğŸ§  **Pregunta 4**
Â¿CuÃ¡l es la funciÃ³n de activaciÃ³n mÃ¡s usada en capas ocultas?

A. Threshold
B. Sigmoid
C. Tanh
D. ReLU

âœ… Correcta: D
ğŸ§¾ ExplicaciÃ³n: ReLU es eficiente, rÃ¡pida y permite manejar grandes redes, por eso es la mÃ¡s utilizada en capas ocultas.

---

ğŸ§  **Pregunta 5**
Â¿CuÃ¡l es el propÃ³sito de la normalizaciÃ³n o estandarizaciÃ³n de datos?

A. Aumentar el nÃºmero de entradas
B. Disminuir el aprendizaje de la red
C. Acelerar la convergencia del entrenamiento
D. Eliminar valores atÃ­picos

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Al mantener los valores en un rango uniforme, la red aprende mÃ¡s rÃ¡pido y con mayor estabilidad.

---

ğŸ§  **Pregunta 6**
Â¿QuÃ© significa el tÃ©rmino â€œbackpropagationâ€?

A. ConexiÃ³n inversa entre neuronas
B. Proceso de enviar seÃ±ales entre neuronas
C. Ajuste de pesos basado en el error
D. PredicciÃ³n final del modelo

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Backpropagation es el proceso por el cual el error se propaga hacia atrÃ¡s para ajustar los pesos y mejorar el modelo.

---

ğŸ§  **Pregunta 7**
Â¿QuÃ© tipo de salida tiene un modelo de regresiÃ³n en redes neuronales?

A. Un nÃºmero entre 0 y 1
B. Un nÃºmero entero
C. Una clase especÃ­fica
D. Un valor numÃ©rico continuo

âœ… Correcta: D
ğŸ§¾ ExplicaciÃ³n: En regresiÃ³n, la salida es un nÃºmero continuo como un precio, temperatura, etc.

---

ğŸ§  **Pregunta 8**
Â¿QuÃ© representa una Ã©poca (epoch) en el entrenamiento de redes neuronales?

A. Una actualizaciÃ³n de un peso
B. Una observaciÃ³n procesada
C. Un ciclo completo por todos los datos
D. Un tipo de funciÃ³n de activaciÃ³n

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Una Ã©poca es una pasada completa de todos los datos de entrenamiento por la red para actualizar los pesos.

---

ğŸ§  **Pregunta 9**
Â¿Para quÃ© sirve la funciÃ³n de activaciÃ³n sigmoid?

A. Prevenir sobreajuste
B. Crear mÃºltiples salidas
C. Generar una salida entre 0 y 1 interpretada como probabilidad
D. Activar neuronas negativas

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La funciÃ³n sigmoide convierte la entrada en un valor entre 0 y 1, ideal para clasificaciones binarias.

---

ğŸ§  **Pregunta 10**
Â¿QuÃ© combinaciÃ³n de funciones es recomendable en una red neuronal para clasificaciÃ³n binaria?

A. Capa oculta con Tanh, salida con Threshold
B. Capa oculta con ReLU, salida con Sigmoid
C. Capa oculta con Threshold, salida con ReLU
D. Capa oculta con Sigmoid, salida con ReLU

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: ReLU permite un aprendizaje eficiente en capas ocultas, y Sigmoid es ideal para obtener una probabilidad final en problemas binarios.

---

Perfecto. AquÃ­ tienes **30 preguntas mÃ¡s** tipo examen, con opciones, respuesta correcta y explicaciÃ³n, basadas en la lectura que enviaste sobre redes neuronales artificiales:

---

ğŸ§  **Pregunta 11**
Â¿QuÃ© parte de una neurona biolÃ³gica recibe las seÃ±ales de entrada?

A. Soma
B. AxÃ³n
C. Dendritas
D. Sinapsis

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Las dendritas son ramificaciones que reciben seÃ±ales de otras neuronas.

---

ğŸ§  **Pregunta 12**
En una neurona artificial, Â¿quÃ© representa el bias?

A. Un tipo de entrada fija
B. Un valor que ajusta la salida final
C. La importancia de la funciÃ³n de activaciÃ³n
D. Un error aleatorio

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: El bias permite ajustar la salida incluso cuando todas las entradas son cero, ayudando a mejorar el aprendizaje.

---

ğŸ§  **Pregunta 13**
Â¿QuÃ© hace la funciÃ³n de activaciÃ³n?

A. Multiplica los pesos por las entradas
B. Calcula el error del modelo
C. Decide si una neurona se activa o no
D. Normaliza los datos

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La funciÃ³n de activaciÃ³n transforma la suma ponderada en la salida de la neurona.

---

ğŸ§  **Pregunta 14**
Â¿QuÃ© rango de valores puede producir la funciÃ³n tanh?

A. Entre 0 y 1
B. Entre -1 y 1
C. Desde 0 hasta infinito
D. Solo valores positivos

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Tanh es una funciÃ³n centrada en cero que produce valores entre -1 y 1.

---

ğŸ§  **Pregunta 15**
Â¿Por quÃ© es Ãºtil la funciÃ³n ReLU?

A. Genera probabilidades
B. Elimina entradas negativas
C. Reduce el tamaÃ±o de la red
D. Mejora el tiempo de convergencia

âœ… Correcta: D
ğŸ§¾ ExplicaciÃ³n: ReLU es eficiente, evita el problema del desvanecimiento del gradiente y permite un entrenamiento mÃ¡s rÃ¡pido.

---

ğŸ§  **Pregunta 16**
Â¿QuÃ© sucede si no normalizas los datos antes de entrenar una red?

A. El modelo serÃ¡ mÃ¡s preciso
B. Los pesos serÃ¡n irrelevantes
C. El entrenamiento serÃ¡ mÃ¡s lento y menos estable
D. No se podrÃ¡ usar la funciÃ³n sigmoid

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Normalizar ayuda a que todos los datos estÃ©n en rangos similares, mejorando la estabilidad del entrenamiento.

---

ğŸ§  **Pregunta 17**
Â¿QuÃ© funciÃ³n de activaciÃ³n produce salidas tipo "todo o nada"?

A. ReLU
B. Sigmoid
C. Threshold
D. Tanh

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Threshold o escalÃ³n es una funciÃ³n binaria que activa la neurona si se pasa un umbral.

---

ğŸ§  **Pregunta 18**
Â¿CuÃ¡l es el resultado de una red con mÃºltiples capas ocultas?

A. Menor tiempo de entrenamiento
B. MÃ¡s precisiÃ³n y capacidad de detectar patrones complejos
C. Menor uso de funciones de activaciÃ³n
D. No mejora respecto a una sola capa

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: MÃ¡s capas permiten que la red aprenda representaciones mÃ¡s abstractas y profundas.

---

ğŸ§  **Pregunta 19**
Â¿QuÃ© es una observaciÃ³n en el contexto de redes neuronales?

A. Una columna en el dataset
B. Un dato fuera de lo comÃºn
C. Una fila de datos con entradas y salida esperada
D. Un error del modelo

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Una observaciÃ³n es un conjunto de caracterÃ­sticas (una fila) que se usa para entrenar o predecir.

---

ğŸ§  **Pregunta 20**
Â¿QuÃ© significa que una neurona artificial estÃ© â€œactivadaâ€?

A. Que ha sido eliminada
B. Que su salida es diferente de cero
C. Que ha recibido muchas entradas
D. Que no se puede ajustar

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: La activaciÃ³n ocurre cuando la suma ponderada pasa por la funciÃ³n de activaciÃ³n y produce una salida significativa.

---

ğŸ§  **Pregunta 21**
Â¿QuÃ© parte del modelo ajusta los pesos para mejorar su rendimiento?

A. La capa de entrada
B. La funciÃ³n de activaciÃ³n
C. El proceso de entrenamiento
D. La normalizaciÃ³n

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Durante el entrenamiento, los pesos se ajustan para minimizar el error entre predicciÃ³n y valor real.

---

ğŸ§  **Pregunta 22**
Â¿QuÃ© sucede si usamos una red sin funciÃ³n de activaciÃ³n?

A. Se convierte en un clasificador binario
B. No puede representar relaciones no lineales
C. Se vuelve mÃ¡s precisa
D. No requiere entrenamiento

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Las funciones de activaciÃ³n permiten que la red aprenda relaciones no lineales. Sin ellas, solo aprende funciones lineales.

---

ğŸ§  **Pregunta 23**
Â¿CuÃ¡l es el propÃ³sito de la funciÃ³n de costo?

A. Calcular los pesos iniciales
B. Determinar la cantidad de capas necesarias
C. Medir el error entre la predicciÃ³n y el valor real
D. Eliminar neuronas innecesarias

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La funciÃ³n de costo evalÃºa quÃ© tan mal estÃ¡ prediciendo el modelo, lo cual guÃ­a el ajuste de pesos.

---

ğŸ§  **Pregunta 24**
En una red neuronal, Â¿quÃ© ocurre en cada Ã©poca?

A. Se ajustan los pesos al azar
B. Se entrena con una fila de datos
C. Se entrena con todo el conjunto de datos una vez
D. Se eliminan neuronas inactivas

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Una Ã©poca representa una pasada completa por todos los datos de entrenamiento para ajustar pesos.

---

ğŸ§  **Pregunta 25**
Â¿QuÃ© tipo de problemas resuelve la red si la salida es continua?

A. ClasificaciÃ³n
B. RegresiÃ³n
C. Agrupamiento
D. ReducciÃ³n de dimensionalidad

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Cuando la salida es un nÃºmero continuo, la red estÃ¡ realizando una tarea de regresiÃ³n.

---

ğŸ§  **Pregunta 26**
Â¿En quÃ© parte de la red se realiza la predicciÃ³n final?

A. En la capa de entrada
B. En las capas ocultas
C. En la capa de salida
D. En los pesos

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La capa de salida produce el valor final predicho por el modelo, sea clasificaciÃ³n o regresiÃ³n.

---

ğŸ§  **Pregunta 27**
Â¿QuÃ© permite que una red neuronal aprenda?

A. El cambio constante de funciones de activaciÃ³n
B. La retropropagaciÃ³n del error y ajuste de pesos
C. El uso de entradas siempre iguales
D. Tener muchas capas de salida

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: La red aprende al ajustar los pesos mediante retropropagaciÃ³n, guiada por el error de predicciÃ³n.

---

ğŸ§  **Pregunta 28**
Â¿CuÃ¡l es el primer paso al recibir una observaciÃ³n en la red?

A. Calcular la funciÃ³n de activaciÃ³n
B. Predecir el resultado
C. Recibir las entradas y multiplicarlas por los pesos
D. Comparar con el valor real

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Primero, se reciben las entradas y se combinan con los pesos antes de aplicar cualquier funciÃ³n.

---

ğŸ§  **Pregunta 29**
Â¿QuÃ© tipo de salida se usa para clasificaciones multiclase?

A. Un solo valor continuo
B. Una variable booleana
C. Varias salidas dummy o codificadas
D. Un nÃºmero negativo

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: En clasificaciÃ³n multiclase, se usa una salida por clase y se codifican como variables dummy (0 o 1).

---

ğŸ§  **Pregunta 30**
Â¿QuÃ© analogÃ­a se usa para describir cÃ³mo trabajan las neuronas en conjunto?

A. Un motor de coche
B. Una ecuaciÃ³n matemÃ¡tica
C. Una colonia de hormigas
D. Un archivo comprimido

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Como las hormigas, cada neurona individual hace poco, pero juntas logran tareas complejas.

---

ğŸ§  **Pregunta 31**
Â¿QuÃ© representa el sÃ­mbolo \$\hat{y}\$ en una red neuronal?

A. El valor real observado
B. El promedio de las entradas
C. La predicciÃ³n del modelo
D. El error de predicciÃ³n

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: \$\hat{y}\$ es la salida predicha por la red neuronal para una observaciÃ³n.

---

ğŸ§  **Pregunta 32**
Â¿CuÃ¡l es el objetivo final de una red neuronal entrenada?

A. Minimizar el nÃºmero de neuronas
B. Predecir con precisiÃ³n sobre nuevos datos
C. Cambiar sus funciones de activaciÃ³n
D. Reducir el nÃºmero de Ã©pocas

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Una red bien entrenada debe generalizar correctamente y predecir bien sobre datos no vistos.

---

ğŸ§  **Pregunta 33**
Â¿QuÃ© parte de una neurona artificial se asemeja al axÃ³n biolÃ³gico?

A. Las entradas
B. El peso
C. La salida
D. La sinapsis

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El axÃ³n transmite la salida de una neurona a otra, lo que equivale al output en una neurona artificial.

---

ğŸ§  **Pregunta 34**
Â¿QuÃ© sucede con la salida si una entrada negativa pasa por ReLU?

A. Se convierte en 1
B. Se mantiene igual
C. Se transforma en 0
D. Se invierte el signo

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La funciÃ³n ReLU convierte cualquier valor negativo en 0, bloqueando la activaciÃ³n.

---

ğŸ§  **Pregunta 35**
Â¿CuÃ¡ndo se detiene el entrenamiento de una red neuronal?

A. Cuando ya no hay entradas nuevas
B. Cuando el error es cero
C. Cuando se alcanza el nÃºmero de Ã©pocas o se minimiza el error
D. DespuÃ©s de la primera predicciÃ³n

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El entrenamiento se detiene al alcanzar un nÃºmero de Ã©pocas o cuando el error ya no mejora.


---

ğŸ§  **Pregunta 36**
Â¿QuÃ© relaciÃ³n hay entre pesos y entradas en una neurona artificial?

A. Se suman directamente
B. Las entradas determinan el nÃºmero de pesos
C. Cada entrada se multiplica por su peso correspondiente
D. Los pesos reemplazan a las entradas

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Cada entrada se multiplica por un peso que representa su importancia para la predicciÃ³n.

---

ğŸ§  **Pregunta 37**
Â¿QuÃ© nombre recibe la suma ponderada de entradas y pesos mÃ¡s el bias?

A. Salida
B. Error
C. Entrada neta
D. ActivaciÃ³n

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La entrada neta es el resultado de combinar entradas y pesos, mÃ¡s el bias, antes de aplicar la funciÃ³n de activaciÃ³n.

---

ğŸ§  **Pregunta 38**
Â¿CuÃ¡l es la ventaja de usar la funciÃ³n Tanh en lugar de Sigmoid?

A. Es mÃ¡s rÃ¡pida
B. Tiene un rango mayor
C. EstÃ¡ centrada en cero
D. Requiere menos datos

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Tanh produce valores entre -1 y 1, lo cual puede facilitar el aprendizaje al estar centrada en cero.

---

ğŸ§  **Pregunta 39**
Â¿QuÃ© se debe hacer si los datos tienen escalas muy distintas?

A. Aplicar dropout
B. Normalizarlos o estandarizarlos
C. Usar mÃ¡s neuronas
D. Cambiar la funciÃ³n de activaciÃ³n

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: La normalizaciÃ³n y estandarizaciÃ³n ajustan los datos para que tengan rangos similares y el modelo aprenda mejor.

---

ğŸ§  **Pregunta 40**
Â¿QuÃ© determina el nÃºmero de neuronas en la capa de salida?

A. El nÃºmero de capas ocultas
B. El nÃºmero de entradas
C. El tipo de problema (regresiÃ³n, binaria, multiclase)
D. El valor del bias

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La salida depende del tipo de problema: 1 neurona para regresiÃ³n o binaria, varias para clasificaciÃ³n multiclase.

---

ğŸ§  **Pregunta 41**
Â¿QuÃ© funciÃ³n de activaciÃ³n usarÃ­as para una red neuronal que clasifica entre manzana, plÃ¡tano y naranja?

A. Threshold
B. Tanh
C. Softmax
D. ReLU

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Softmax convierte los valores en probabilidades que suman 1, ideal para clasificaciÃ³n multiclase.

---

ğŸ§  **Pregunta 42**
Â¿QuÃ© representa la sinapsis en una red neuronal artificial?

A. La funciÃ³n de activaciÃ³n
B. El proceso de entrenamiento
C. La conexiÃ³n con un peso entre dos neuronas
D. El conjunto de capas ocultas

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La sinapsis artificial es el enlace con peso entre una neurona y otra.

---

ğŸ§  **Pregunta 43**
Â¿QuÃ© hace la red si una propiedad tiene mÃ¡s de 100 aÃ±os, segÃºn el ejemplo de neuronas?

A. Ignora la edad
B. Reduce el precio
C. Activa una neurona especializada
D. Cambia la funciÃ³n de activaciÃ³n

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Se activa una neurona diseÃ±ada para detectar propiedades histÃ³ricas con mÃ¡s de 100 aÃ±os.

---

ğŸ§  **Pregunta 44**
Â¿Por quÃ© ReLU es mÃ¡s eficiente que sigmoid en redes profundas?

A. Es mÃ¡s precisa
B. Tiene un rango negativo
C. No activa valores negativos y es computacionalmente mÃ¡s simple
D. Funciona solo con datos pequeÃ±os

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: ReLU es rÃ¡pida y evita cÃ¡lculos innecesarios con entradas negativas (las convierte en 0).

---

ğŸ§  **Pregunta 45**
Â¿QuÃ© tipo de modelo es una red sin capas ocultas y con funciÃ³n sigmoid?

A. RegresiÃ³n lineal
B. Ãrbol de decisiÃ³n
C. RegresiÃ³n logÃ­stica
D. K-NN

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Una red sin capas ocultas con activaciÃ³n sigmoide equivale a una regresiÃ³n logÃ­stica.

---

ğŸ§  **Pregunta 46**
Â¿QuÃ© significa que los pesos se ajusten en direcciÃ³n opuesta al gradiente?

A. Aumentan su valor
B. Disminuyen en cada Ã©poca
C. Buscan minimizar el error
D. Cambian aleatoriamente

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Se actualizan en la direcciÃ³n que reduce la funciÃ³n de costo, lo que mejora las predicciones.

---

ğŸ§  **Pregunta 47**
Â¿CuÃ¡l es el propÃ³sito del bias en una neurona?

A. Impedir que se activen todas las neuronas
B. Normalizar las entradas
C. Desplazar la funciÃ³n de activaciÃ³n
D. Representar el error

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El bias ajusta el punto de activaciÃ³n de la funciÃ³n, actuando como un desplazamiento.

---

ğŸ§  **Pregunta 48**
Â¿QuÃ© sucede si el modelo tiene muchos errores durante el entrenamiento?

A. Se reinician los pesos
B. Se ajustan los pesos usando backpropagation
C. Se elimina una capa
D. Se detiene el entrenamiento

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Los errores se retropropagan y permiten ajustar los pesos para reducir ese error.

---

ğŸ§  **Pregunta 49**
Â¿QuÃ© representa el valor de salida de una funciÃ³n sigmoid?

A. Una clase exacta
B. Una cantidad continua
C. Una probabilidad entre 0 y 1
D. El promedio de los pesos

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La funciÃ³n sigmoide devuelve un valor entre 0 y 1 que puede interpretarse como probabilidad.

---

ğŸ§  **Pregunta 50**
Â¿QuÃ© pasa si el nÃºmero de Ã©pocas es demasiado alto?

A. La red no aprenderÃ¡
B. Puede ocurrir sobreajuste (overfitting)
C. Se eliminan neuronas
D. El modelo se vuelve lineal

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Demasiadas Ã©pocas pueden hacer que el modelo aprenda demasiado bien el entrenamiento y falle con nuevos datos.

---

ğŸ§  **Pregunta 51**
Â¿QuÃ© tÃ©cnica se usa para procesar muchas observaciones al mismo tiempo?

A. RetroalimentaciÃ³n
B. Minibatch
C. Backpropagation
D. NormalizaciÃ³n

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Minibatch permite que varias observaciones se procesen en paralelo, acelerando el entrenamiento.

---

ğŸ§  **Pregunta 52**
Â¿CuÃ¡l es el flujo bÃ¡sico de una red neuronal simple?

A. Salida â†’ Entrada â†’ Oculta
B. Entrada â†’ Salida â†’ Oculta
C. Entrada â†’ Oculta â†’ Salida
D. Bias â†’ Salida â†’ Oculta

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El flujo de informaciÃ³n siempre va desde la entrada, pasa por capas ocultas y termina en la salida.

---

ğŸ§  **Pregunta 53**
Â¿QuÃ© valor de activaciÃ³n tiene una ReLU con entrada de -5?

A. -5
B. 5
C. 0
D. 1

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: ReLU convierte todos los valores negativos en 0.

---

ğŸ§  **Pregunta 54**
Â¿QuÃ© pasarÃ­a si se usaran solo funciones lineales en todas las capas?

A. El modelo no se entrena
B. El modelo no aprende patrones complejos
C. La funciÃ³n de costo no funciona
D. Las capas ocultas no existen

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Las funciones lineales no pueden capturar relaciones no lineales complejas, por eso se usan activaciones.

---

ğŸ§  **Pregunta 55**
Â¿CuÃ¡l es el objetivo del descenso por gradiente?

A. Aumentar los errores
B. Hacer mÃ¡s rÃ¡pida la predicciÃ³n
C. Minimizar la funciÃ³n de costo
D. Predecir el valor real sin entrenamiento

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Es una tÃ©cnica que ajusta pesos para reducir el error, o funciÃ³n de costo.

---

ğŸ§  **Pregunta 56**
Â¿QuÃ© puede pasar si no usamos funciÃ³n de activaciÃ³n?

A. Las capas ocultas no procesan
B. El modelo se detiene
C. El modelo no podrÃ¡ clasificar correctamente
D. El bias no se actualiza

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Sin funciÃ³n de activaciÃ³n, el modelo se reduce a una combinaciÃ³n lineal y no puede aprender patrones complejos.

---

ğŸ§  **Pregunta 57**
Â¿CuÃ¡l de estas funciones tiene una salida en el rango \[0, âˆ)?

A. Threshold
B. Sigmoid
C. ReLU
D. Tanh

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: ReLU solo da valores mayores o iguales a 0, ideal para capas ocultas.

---

ğŸ§  **Pregunta 58**
Â¿QuÃ© hace la red despuÃ©s de aplicar la funciÃ³n de activaciÃ³n?

A. Ajusta los pesos
B. Calcula la media
C. Pasa la salida a la siguiente capa
D. Borra las entradas

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La salida activada se transmite a las neuronas siguientes.

---

ğŸ§  **Pregunta 59**
Â¿CuÃ¡l es el rol de las capas ocultas?

A. Normalizar los datos
B. Combinar pesos y bias
C. Aprender patrones intermedios entre entrada y salida
D. Aplicar funciÃ³n de costo

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Las capas ocultas permiten que la red detecte relaciones no evidentes y construya abstracciones.

---

ğŸ§  **Pregunta 60**
Â¿QuÃ© resultado espera una red neuronal en una tarea de clasificaciÃ³n binaria?

A. Un nÃºmero negativo
B. Un valor booleano
C. Una probabilidad entre 0 y 1
D. Una etiqueta textual

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: En clasificaciÃ³n binaria, la red devuelve una probabilidad que puede ser umbralizada (por ejemplo, >0.5 es "sÃ­").

---
