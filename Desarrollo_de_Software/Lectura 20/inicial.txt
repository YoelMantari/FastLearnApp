ğŸ§  Pregunta 1
Â¿CuÃ¡l es la principal funciÃ³n de un stub en el contexto de pruebas unitarias?

A. Registrar todas las llamadas a una funciÃ³n
B. Simular errores de red y latencias
C. Proveer respuestas fijas a peticiones externas
D. Verificar que una funciÃ³n fue llamada con argumentos especÃ­ficos

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Los stubs estÃ¡n diseÃ±ados para devolver valores predefinidos de forma rÃ¡pida y predecible, evitando la necesidad de contactar con servicios externos durante las pruebas.

ğŸ§  Pregunta 2
Â¿QuÃ© ventaja clave ofrecen los mocks frente a los stubs?

A. Permiten evitar el uso de contenedores
B. Registran informaciÃ³n sobre llamadas como argumentos y frecuencia
C. Generan datos de prueba automÃ¡ticamente
D. Evitan que se requiera cobertura de cÃ³digo

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Los mocks no solo simulan respuestas, sino que tambiÃ©n registran metadatos de interacciÃ³n, como nÃºmero de llamadas y argumentos usados, permitiendo aserciones de comportamiento.

ğŸ§  Pregunta 3
Â¿QuÃ© tipo de doble de prueba se utiliza cuando se necesita una implementaciÃ³n funcional pero simplificada de una dependencia real?

A. Stub
B. Mock
C. Dummy
D. Fake

âœ… Correcta: D
ğŸ§¾ ExplicaciÃ³n: Un fake mantiene parte de la lÃ³gica real y permite ejecutar pruebas funcionales sin requerir la infraestructura de producciÃ³n.

ğŸ§  Pregunta 4
Â¿CuÃ¡l es una desventaja clave del enfoque de pruebas mockist (Detroit School)?

A. Las pruebas son demasiado lentas para ejecutarse en pipelines
B. El uso de mocks impide medir la cobertura
C. Las pruebas pueden ser frÃ¡giles ante cambios internos del cÃ³digo
D. No permite simular errores como timeouts o excepciones

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Las pruebas mockist son rÃ¡pidas, pero pueden romperse fÃ¡cilmente ante cambios menores en la implementaciÃ³n, incluso si el comportamiento externo sigue siendo correcto.

ğŸ§  Pregunta 5
Â¿CuÃ¡l es el objetivo de usar side_effect en un mock dentro de pytest?

A. Ejecutar un test varias veces automÃ¡ticamente
B. Simular comportamiento dinÃ¡mico o lanzar excepciones
C. Generar fixtures de forma automÃ¡tica
D. Asegurar que un test no dependa del sistema operativo

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: side_effect permite definir respuestas dinÃ¡micas, lanzar errores o simular secuencias de llamadas, enriqueciendo el realismo del doble de prueba.

ğŸ§  Pregunta 6
Â¿QuÃ© ventaja proporciona el uso de stubs en los hooks de pre-commit?

A. Permite ejecutar pruebas de integraciÃ³n en paralelo
B. Garantiza validaciÃ³n de contratos de red
C. Acelera la retroalimentaciÃ³n al ejecutar tests en milisegundos
D. Evita que se necesiten pruebas unitarias

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Al usar stubs en pre-commit, se aÃ­slan las dependencias y se obtienen resultados rÃ¡pidos, mejorando la eficiencia del flujo DevOps.

ğŸ§  Pregunta 7
Â¿CuÃ¡l es el rol principal de un dummy en una prueba?

A. Ejecutar una lÃ³gica de negocio real
B. Registrar interacciones con un servicio
C. Cumplir con la firma del mÃ©todo sin funcionalidad
D. Validar los contratos entre servicios

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Los dummies son objetos sin comportamiento que se usan solo para completar parÃ¡metros obligatorios.

ğŸ§  Pregunta 8
Â¿QuÃ© patrÃ³n se recomienda para evitar modificar el cuerpo de un test al aÃ±adir nuevos casos?

A. Uso de fixtures
B. InversiÃ³n de dependencias
C. ParametrizaciÃ³n con pytest
D. TÃ©cnica de monkey patching

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La parametrizaciÃ³n permite extender la variedad de casos sin cambiar la lÃ³gica del test, favoreciendo el Principio Open/Closed.

ğŸ§  Pregunta 9
Â¿CuÃ¡l es una desventaja del enfoque classical (London School) en pruebas?

A. No permite usar mocks
B. Tiene alta fragilidad ante cambios internos
C. Requiere entornos complejos y tiempos largos de ejecuciÃ³n
D. Es incompatible con pipelines de CI/CD

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Las pruebas classical reproducen la realidad con mayor fidelidad, pero a costa de un tiempo de ejecuciÃ³n mÃ¡s elevado y mayor complejidad de mantenimiento.

ğŸ§  Pregunta 10
Â¿En quÃ© situaciÃ³n se recomienda el uso de autospec al crear mocks?

A. Cuando se necesitan respuestas secuenciales
B. Para validar firmas reales y evitar parÃ¡metros invÃ¡lidos
C. Cuando se desea omitir dependencias opcionales
D. Para evitar el uso de fixtures

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: autospec genera mocks basados en la interfaz real, previniendo errores por llamadas incorrectas y garantizando la coherencia.

ğŸ§  Pregunta 11
Â¿QuÃ© diferencia principal tienen los fakes respecto a los mocks?

A. Los fakes no pueden ejecutarse en pruebas unitarias
B. Los mocks simulan comportamiento real, los fakes no
C. Los fakes implementan parte de la lÃ³gica real
D. Los mocks requieren conexiÃ³n a bases de datos

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Los fakes tienen una lÃ³gica funcional simplificada, Ãºtil para pruebas mÃ¡s cercanas a la producciÃ³n sin necesidad de servicios reales.

ğŸ§  Pregunta 12
Â¿CuÃ¡l es el objetivo del patching localizado?

A. Simular todo el entorno en tiempo de compilaciÃ³n
B. Aplicar mocks solo dentro del bloque o funciÃ³n de prueba
C. Mantener la cobertura al 100%
D. Ejecutar fixtures de forma asÃ­ncrona

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: El patching localizado restringe el alcance del mock a una funciÃ³n o bloque especÃ­fico, reduciendo efectos colaterales.

ğŸ§  Pregunta 13
Â¿CuÃ¡l es el propÃ³sito del marcador @pytest.mark.xfail?

A. Ejecutar pruebas que deben pasar bajo cualquier condiciÃ³n
B. Ignorar la prueba sin mostrarla en el reporte
C. Marcar pruebas con fallos esperados sin interrumpir el pipeline
D. Repetir la prueba mÃºltiples veces con distintos parÃ¡metros

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: xfail se utiliza para seÃ±alar fallos conocidos en pruebas sin romper la ejecuciÃ³n general, aportando trazabilidad.

ğŸ§  Pregunta 14
Â¿QuÃ© validaciÃ³n ofrece mock.assert_called_once_with(...)?

A. Que se haya llamado con al menos un argumento
B. Que el mock fue llamado al menos una vez
C. Que el mock fue invocado exactamente una vez con los argumentos dados
D. Que no hubo ninguna llamada al mock

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Esta aserciÃ³n garantiza precisiÃ³n en la interacciÃ³n esperada: una sola llamada con parÃ¡metros exactos.

ğŸ§  Pregunta 15
Â¿QuÃ© tipo de test se beneficiarÃ­a mÃ¡s de un fake que simula una base de datos?

A. Test de UI
B. Test unitario
C. Test de integraciÃ³n ligera
D. Test de performance

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Los fakes permiten simular partes funcionales del sistema, como bases de datos, sin desplegar infraestructura real.

ğŸ§  Pregunta 16
Â¿CuÃ¡l es una desventaja del uso excesivo de mocks?

A. Los mocks incrementan el tiempo de ejecuciÃ³n del pipeline
B. Pueden ocultar errores reales al depender de implementaciones simuladas
C. Requieren levantar contenedores adicionales
D. No se pueden usar en pruebas automÃ¡ticas

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Un uso abusivo de mocks puede generar tests que pasan sin detectar problemas reales en entornos de producciÃ³n.

ğŸ§  Pregunta 17
Â¿QuÃ© permite validar el historial de llamadas (call_args_list) en un mock?

A. QuÃ© errores se lanzaron en producciÃ³n
B. El orden y argumentos de todas las invocaciones realizadas
C. QuÃ© datos fueron persistidos en una base de datos
D. QuÃ© pruebas han fallado y cuÃ¡les no

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: call_args_list permite inspeccionar todas las llamadas a un mock, incluyendo sus parÃ¡metros y orden de ejecuciÃ³n.

ğŸ§  Pregunta 18
Â¿CuÃ¡l es el beneficio de pytest-benchmark en el contexto DevOps?

A. Automatizar el versionado de mocks
B. Registrar tiempos de ejecuciÃ³n para detectar regresiones de rendimiento
C. Evitar usar side_effect
D. Simular mÃºltiples respuestas de red

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: pytest-benchmark permite medir el tiempo de ejecuciÃ³n de funciones clave y comparar rendimientos entre ejecuciones.

ğŸ§  Pregunta 19
Â¿QuÃ© garantiza el principio Open/Closed aplicado a los tests?

A. Los tests pueden conectarse directamente con staging
B. Los tests deben cubrir todo el sistema
C. Los tests se pueden extender sin modificar su cÃ³digo original
D. Los tests no deben depender de frameworks externos

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El principio OCP fomenta que los tests se mantengan estables, aÃ±adiendo nuevos escenarios mediante parametrizaciÃ³n sin alterar el cuerpo del test.

ğŸ§  Pregunta 20
Â¿CuÃ¡ndo es preferible usar patching holÃ­stico?

A. En pruebas unitarias con mocks simples
B. Cuando el comportamiento depende del sistema operativo
C. En pruebas de integraciÃ³n que reutilizan una configuraciÃ³n comÃºn
D. Para evitar el uso de fixtures

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El patching holÃ­stico se usa cuando muchos tests necesitan la misma simulaciÃ³n, optimizando la configuraciÃ³n comÃºn a nivel de sesiÃ³n o mÃ³dulo.

ğŸ§  Pregunta 21
Â¿CuÃ¡l es un buen criterio para decidir entre usar mocks o un entorno real?

A. La cantidad de lÃ­neas de cÃ³digo
B. La frecuencia de commits
C. El tiempo disponible para pruebas
D. El tipo de validaciÃ³n: comportamiento versus integraciÃ³n

âœ… Correcta: D
ğŸ§¾ ExplicaciÃ³n: Para validar interacciones especÃ­ficas, los mocks son Ãºtiles; para flujos integrados de extremo a extremo, es mejor usar entornos reales o fakes.

ğŸ§  Pregunta 22
Â¿QuÃ© componente de un test permite simular una excepciÃ³n como TimeoutError?

A. Un fake
B. pytest.mark.xfail
C. side_effect en un mock
D. autospec

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: side_effect permite lanzar excepciones simuladas como parte del comportamiento del mock.

ğŸ§  Pregunta 23
Â¿Por quÃ© es importante mantener los mocks alineados con la API real?

A. Para no romper el entorno de staging
B. Porque la documentaciÃ³n se genera automÃ¡ticamente
C. Para evitar inconsistencias entre pruebas y producciÃ³n
D. Porque reduce el uso de recursos computacionales

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Cuando la API real cambia, los mocks deben actualizarse para evitar desincronizaciÃ³n y falsos positivos en pruebas.

ğŸ§  Pregunta 24
Â¿QuÃ© tÃ©cnica permite simular respuestas paginadas en una API usando mocks?

A. autospec con decorators
B. side_effect con generadores
C. pytest.mark.xfail con fixtures
D. patch con skipif

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Al usar generadores con side_effect, se pueden simular varias respuestas secuenciales como una API paginada.

ğŸ§  Pregunta 25
Â¿CuÃ¡l es una buena prÃ¡ctica al usar fixtures para mocks en pytest?

A. Crear un nuevo stub por cada test manualmente
B. Configurar respuestas dentro del test y no en la fixture
C. Definir fixtures reutilizables con alcance controlado
D. Evitar parametrizaciÃ³n por temas de rendimiento

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Reutilizar fixtures permite mantener el cÃ³digo limpio y controlado, optimizando su uso segÃºn el alcance necesario (funciÃ³n, mÃ³dulo, sesiÃ³n).

ğŸ§  Pregunta 26
Â¿CuÃ¡l es la principal diferencia entre un spy y un mock?

A. El spy no permite verificar argumentos
B. El spy ejecuta la lÃ³gica real y registra llamadas
C. El mock siempre lanza excepciones
D. El mock se usa solo para funciones asÃ­ncronas

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: El spy actÃºa como un envoltorio del objeto real, permitiendo registrar llamadas sin alterar su comportamiento.

ğŸ§  Pregunta 27
Â¿Para quÃ© se utiliza monkeypatch en pytest?

A. Crear dummies sin lÃ³gica
B. Medir cobertura de ramas
C. Parchear funciones o mÃ©todos durante los tests
D. Repetir tests fallidos automÃ¡ticamente

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: monkeypatch permite cambiar atributos, funciones o mÃ©todos temporalmente durante la ejecuciÃ³n de un test.

ğŸ§  Pregunta 28
Â¿QuÃ© permite verificar mock.call_args_list?

A. El nÃºmero de lÃ­neas cubiertas por prueba
B. Los argumentos de todas las llamadas hechas a un mock
C. La conexiÃ³n a una API externa real
D. La cantidad de errores de un test

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: call_args_list es una lista que contiene todos los argumentos con los que se llamÃ³ al mock en orden.

ğŸ§  Pregunta 29
Â¿En quÃ© caso se recomienda el uso de @pytest.mark.skip?

A. Cuando una prueba estÃ¡ incompleta y falla constantemente
B. Cuando un test depende de condiciones especÃ­ficas no cumplidas
C. Cuando el cÃ³digo no tiene cobertura suficiente
D. Cuando se desea ocultar errores de los pipelines

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: skip permite omitir pruebas que no deben ejecutarse en ciertos contextos, por ejemplo, sistemas operativos incompatibles.

ğŸ§  Pregunta 30
Â¿Por quÃ© se recomienda limitar la profundidad de mocks en una prueba?

A. Porque los mocks no son compatibles con Python 3
B. Porque los mocks incrementan el tamaÃ±o de los binarios
C. Porque usar muchos mocks puede indicar exceso de acoplamiento
D. Porque impiden ejecutar fixtures

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Si una prueba requiere muchos mocks, puede ser una seÃ±al de que se estÃ¡ probando demasiado o hay fuerte acoplamiento.

ğŸ§  Pregunta 31
Â¿QuÃ© validaciÃ³n realiza mock.assert_not_called()?

A. Que no se haya ejecutado el test
B. Que el resultado sea falso
C. Que el mock nunca fue invocado durante el test
D. Que haya ocurrido una excepciÃ³n

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Este mÃ©todo verifica que el mock no haya sido llamado en ningÃºn momento durante la ejecuciÃ³n del test.

ğŸ§  Pregunta 32
Â¿QuÃ© permite hacer el decorador @patch()?

A. Convertir un mock en spy
B. Reemplazar temporalmente una funciÃ³n o clase durante el test
C. Hacer que un test se ejecute en todos los sistemas operativos
D. Inyectar automÃ¡ticamente errores

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: @patch reemplaza un objeto en tiempo de ejecuciÃ³n para simular su comportamiento sin modificar el cÃ³digo fuente.

ğŸ§  Pregunta 33
Â¿QuÃ© ventaja ofrece la integraciÃ³n de coverage.py en el pipeline?

A. Elimina la necesidad de pruebas manuales
B. Permite ejecutar los tests en staging
C. Bloquea el merge si no se alcanza una cobertura mÃ­nima
D. Automatiza el versionado del cÃ³digo

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: coverage.py mide quÃ© partes del cÃ³digo son ejecutadas durante las pruebas y puede integrarse con reglas de bloqueo en CI.

ğŸ§  Pregunta 34
Â¿CuÃ¡l es una buena prÃ¡ctica respecto al uso de datos en tests con mocks?

A. Usar siempre datos reales
B. Utilizar fixtures o valores deterministas
C. Generar datos aleatorios en cada ejecuciÃ³n
D. Usar relojes del sistema para crear timestamps

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Para mantener pruebas predecibles y repetibles, se recomienda usar fixtures con datos estÃ¡ticos.

ğŸ§  Pregunta 35
Â¿QuÃ© caracterÃ­stica tiene pytest.mark.xfail(strict=True)?

A. Ignora la prueba si falla
B. La considera un Ã©xito incluso si falla
C. Marca como error si la prueba pasa inesperadamente
D. Desactiva los logs de errores

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: strict=True obliga a que la prueba marcada como xfail falle, y genera error si por alguna razÃ³n pasa.

ğŸ§  Pregunta 36
Â¿QuÃ© se recomienda hacer con las marcas skip y xfail a largo plazo?

A. Dejarlas activas permanentemente
B. Reescribirlas como errores fatales
C. Revisarlas periÃ³dicamente y eliminarlas si ya no aplican
D. Convertirlas en fixtures

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Las marcas deben revisarse para evitar acumular deuda tÃ©cnica o ignorar problemas que ya fueron resueltos.

ğŸ§  Pregunta 37
Â¿Para quÃ© sirve side_effect con generadores en pruebas de paginaciÃ³n?

A. Para registrar llamadas de una API
B. Para simular excepciones controladas
C. Para devolver mÃºltiples respuestas secuenciales
D. Para medir la latencia entre llamadas

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Al usar side_effect con generadores, se pueden simular varias pÃ¡ginas de resultados en llamadas consecutivas.

ğŸ§  Pregunta 38
Â¿CuÃ¡l es un riesgo al usar patching holÃ­stico en tests?

A. Que los mocks se reinicien entre pruebas
B. Que se ralentice el pipeline
C. Que los efectos secundarios se propaguen entre tests
D. Que no se pueda medir cobertura

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Un parche aplicado a nivel de mÃ³dulo o sesiÃ³n puede mantenerse activo entre pruebas y generar efectos colaterales.

ğŸ§  Pregunta 39
Â¿CuÃ¡l es la principal ventaja del enfoque mockist?

A. Requiere menos conocimientos tÃ©cnicos
B. Detecta fallos de integraciÃ³n automÃ¡ticamente
C. AÃ­sla componentes para retroalimentaciÃ³n rÃ¡pida
D. Elimina la necesidad de pruebas de integraciÃ³n

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Mockist busca retroalimentaciÃ³n rÃ¡pida probando unidades individuales con dependencias simuladas.

ğŸ§  Pregunta 40
Â¿QuÃ© escenario es ideal para usar un fake?

A. Probar cÃ³mo responde el sistema a errores de red
B. Ejecutar pruebas unitarias con mocks
C. Reemplazar servicios reales con lÃ³gica funcional simplificada
D. Verificar si un dummy fue llamado

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Los fakes implementan la lÃ³gica de manera simplificada para reemplazar servicios reales en pruebas funcionales.

ğŸ§  Pregunta 41
Â¿CuÃ¡l es una buena mÃ©trica para evaluar el balance entre mocks y pruebas reales en un pipeline?

A. Porcentaje de fixtures reutilizadas
B. Cantidad de lÃ­neas de cÃ³digo
C. MÃ©tricas DORA como tiempo de retroalimentaciÃ³n
D. NÃºmero de pruebas ejecutadas por hora

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Las mÃ©tricas DORA permiten medir el rendimiento de pipelines, incluyendo tiempo de ejecuciÃ³n y frecuencia de fallos.

ğŸ§  Pregunta 42
Â¿QuÃ© implica aplicar el principio de inversiÃ³n de dependencias (DIP) con mocks?

A. Usar una base de datos real en todos los tests
B. Modificar el cÃ³digo para permitir inyecciÃ³n de dependencias simuladas
C. Eliminar el uso de fixtures
D. Integrar los mocks dentro del cÃ³digo de producciÃ³n

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Aplicar DIP permite que el cÃ³digo dependa de abstracciones, facilitando el uso de mocks durante las pruebas.

ğŸ§  Pregunta 43
Â¿QuÃ© permite el uso del parÃ¡metro call_count en un mock?

A. Saber cuÃ¡ntos errores hubo durante una ejecuciÃ³n
B. Medir el rendimiento del pipeline
C. Ver cuÃ¡ntas veces fue invocado un mÃ©todo
D. Simular mÃºltiples respuestas

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: call_count indica el nÃºmero total de veces que se ha llamado al mock.

ğŸ§  Pregunta 44
Â¿CuÃ¡l es un objetivo clave del uso de tÃ©cnicas de mocking en CI/CD?

A. Ejecutar los tests solo al final del ciclo
B. Facilitar el versionado semÃ¡ntico
C. Garantizar feedback rÃ¡pido sin dependencias externas
D. Validar firmas de commits

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Mocking permite simular dependencias y obtener resultados inmediatos sin requerir servicios reales.

ğŸ§  Pregunta 45
Â¿QuÃ© utilidad tiene @pytest.fixture(scope="module")?

A. Ejecutar la fixture una sola vez por archivo
B. Parchear automÃ¡ticamente todos los mÃ©todos del mÃ³dulo
C. Simular errores globales del sistema
D. Activar xfail en todos los tests

âœ… Correcta: A
ğŸ§¾ ExplicaciÃ³n: El scope="module" indica que la fixture se ejecuta solo una vez por mÃ³dulo, reutilizÃ¡ndose en mÃºltiples tests.

ğŸ§  Pregunta 46
Â¿En quÃ© situaciÃ³n es Ãºtil un dummy?

A. Cuando se desea validar el comportamiento real de un objeto
B. Para cumplir con los parÃ¡metros requeridos, sin usarlo realmente
C. Para simular errores de red
D. Cuando se necesita simular llamadas mÃºltiples

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Un dummy se utiliza cuando un parÃ¡metro es obligatorio, pero no tiene ningÃºn rol en la prueba.

ğŸ§  Pregunta 47
Â¿CuÃ¡l es el riesgo de mocks mal configurados respecto a la API real?

A. Reducen la cobertura
B. Ocultan bugs por desincronizaciÃ³n de comportamiento
C. Generan pruebas demasiado lentas
D. No permiten paralelismo

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Si los mocks no reflejan el comportamiento real actualizado, las pruebas pueden pasar sin detectar errores presentes en producciÃ³n.

ğŸ§  Pregunta 48
Â¿QuÃ© patrÃ³n se rompe si se modifican los valores internos de un test parametrizado?

A. Principio de Responsabilidad Ãšnica
B. Principio de SustituciÃ³n de Liskov
C. Principio Open/Closed
D. Principio de InversiÃ³n de Dependencias

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El principio Open/Closed establece que el cÃ³digo debe ser abierto a extensiÃ³n, pero cerrado a modificaciÃ³n.

ğŸ§  Pregunta 49
Â¿QuÃ© permite validar assert_any_call()?

A. Que el mock fue llamado solo una vez
B. Que al menos una de las llamadas coincide con los argumentos esperados
C. Que el test contiene un dummy vÃ¡lido
D. Que el pipeline se ejecutÃ³ con Ã©xito

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Esta funciÃ³n valida que entre todas las llamadas realizadas, al menos una coincidiÃ³ con ciertos argumentos.

ğŸ§  Pregunta 50
Â¿CuÃ¡l es una ventaja del uso de mocks en pre-commits?

A. Permiten ejecutar cÃ³digo en staging
B. Aceleran el feedback del desarrollador antes del push
C. Impiden que se realicen cambios en la base de datos
D. Permiten revisar conflictos de merge

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Ejecutar tests con mocks en pre-commit permite identificar errores rÃ¡pidamente antes de enviar cÃ³digo al repositorio.

