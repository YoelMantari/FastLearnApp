ğŸ§  Pregunta 1
Â¿CuÃ¡l de las siguientes mÃ©tricas ofrece una visiÃ³n mÃ¡s precisa del comportamiento de las decisiones condicionales en el cÃ³digo?

A. Cobertura de funciÃ³n
B. Cobertura de sentencia
C. Cobertura de lÃ­nea
D. Cobertura de rama

âœ… Correcta: D
ğŸ§¾ ExplicaciÃ³n: La cobertura de rama verifica si cada camino posible (true/false) en decisiones condicionales ha sido ejecutado, lo que permite una validaciÃ³n mÃ¡s exhaustiva que simplemente ver si una lÃ­nea se ejecutÃ³.

ğŸ§  Pregunta 2
Â¿QuÃ© mÃ©trica DORA mide el tiempo desde que se realiza un commit hasta que el cambio estÃ¡ disponible en producciÃ³n?

A. Change Failure Rate
B. Deployment Frequency
C. Lead Time for Changes
D. Mean Time to Recovery

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El "Lead Time for Changes" cuantifica la agilidad del equipo al medir cuÃ¡nto tarda un cambio en pasar del commit a estar disponible para los usuarios.

ğŸ§  Pregunta 3
Â¿CuÃ¡l de estas herramientas permite visualizar lÃ­nea por lÃ­nea los cambios en cobertura dentro de un Pull Request?

A. Grafana
B. pytest
C. Coveralls
D. Prometheus

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Coveralls es un servicio en la nube que muestra el diff de cobertura directamente en Pull Requests, ayudando a identificar quÃ© lÃ­neas nuevas estÃ¡n cubiertas o no.

ğŸ§  Pregunta 4
Â¿QuÃ© opciÃ³n describe mejor la utilidad del plugin pytest-benchmark?

A. Ejecuta pruebas de integraciÃ³n
B. Compara resultados de cobertura entre ramas
C. Mide el rendimiento temporal de cada test
D. Publica reportes de errores en GitHub

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: pytest-benchmark mide tiempos de ejecuciÃ³n de tests, permitiendo detectar regresiones de rendimiento y generar estadÃ­sticas detalladas como p50, p95, p99.

ğŸ§  Pregunta 5
Â¿QuÃ© prÃ¡ctica permite desactivar una funcionalidad problemÃ¡tica sin necesidad de hacer un nuevo despliegue?

A. Rollback manual
B. Deploy canary
C. Feature flag
D. Refactor

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Los feature flags permiten activar o desactivar funcionalidades desde configuraciÃ³n, Ãºtil para revertir cambios en producciÃ³n sin redeploy.

ğŸ§  Pregunta 6
Â¿QuÃ© mÃ©trica DORA refleja la estabilidad de los despliegues al medir quÃ© porcentaje de ellos causa fallos en producciÃ³n?

A. MTTR
B. Deployment Frequency
C. Lead Time
D. Change Failure Rate

âœ… Correcta: D
ğŸ§¾ ExplicaciÃ³n: El "Change Failure Rate" indica cuÃ¡ntos despliegues resultan en errores o necesitan rollback, siendo clave para evaluar la estabilidad del pipeline.

ğŸ§  Pregunta 7
Â¿CuÃ¡l es una ventaja de almacenar mÃ©tricas en bases de datos de series de tiempo como Prometheus o InfluxDB?

A. Permiten editar los logs del pipeline
B. Ejecutan automÃ¡ticamente todos los tests
C. Soportan consultas temporales y dashboards
D. Reemplazan al sistema de control de versiones

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Estas bases permiten almacenar datos cronolÃ³gicos, hacer consultas como "promedios de 7 dÃ­as" y construir dashboards visuales.

ğŸ§  Pregunta 8
Â¿QuÃ© acciÃ³n automatizada se puede tomar si el tiempo de test supera en mÃ¡s de un 10% al benchmark anterior?

A. El pipeline se reinicia automÃ¡ticamente
B. Se bloquea el merge del Pull Request
C. Se duplican las pruebas de regresiÃ³n
D. Se elimina la rama en conflicto

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Usando pytest-benchmark --benchmark-fail-max-time-diff, el pipeline puede fallar si hay una regresiÃ³n superior al umbral, bloqueando el merge.

ğŸ§  Pregunta 9
Â¿QuÃ© tipo de cobertura se enfoca en medir cuÃ¡ntas funciones o mÃ©todos han sido invocados por la suite de tests?

A. Cobertura de sentencia
B. Cobertura de lÃ­nea
C. Cobertura de funciÃ³n
D. Cobertura de rama

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La cobertura de funciÃ³n asegura que cada funciÃ³n ha sido llamada al menos una vez, validando la ejecuciÃ³n de unidades conceptuales.

ğŸ§  Pregunta 10
SegÃºn las mÃ©tricas DORA, Â¿cuÃ¡l es el rango ideal del MTTR (Mean Time to Recovery) para un equipo considerado "Elite"?

A. MÃ¡s de una semana
B. Menos de una hora
C. Menos de 24 horas
D. Entre 1 y 2 dÃ­as

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Para un equipo Elite, el MTTR debe ser inferior a 1 hora, lo que indica alta capacidad de respuesta ante fallos en producciÃ³n.

ğŸ§  Pregunta 11
Â¿CuÃ¡l de las siguientes mÃ©tricas se obtiene al dividir las lÃ­neas ejecutadas por las lÃ­neas totales en el cÃ³digo?

A. Cobertura de funciÃ³n
B. Cobertura de sentencia
C. Cobertura de lÃ­nea
D. Cobertura de rama

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La cobertura de lÃ­nea mide cuÃ¡ntas lÃ­neas de cÃ³digo han sido ejecutadas durante las pruebas, ofreciendo una primera aproximaciÃ³n del alcance de la suite.

ğŸ§  Pregunta 12
Â¿QuÃ© ventaja ofrece el uso de --benchmark-compare en pytest-benchmark?

A. Identifica ramas no ejecutadas
B. Genera automÃ¡ticamente reportes HTML
C. Permite comparar ejecuciones actuales con benchmarks anteriores
D. Instala dependencias automÃ¡ticamente

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La opciÃ³n --benchmark-compare permite detectar si los tests actuales son mÃ¡s lentos o mÃ¡s rÃ¡pidos que una ejecuciÃ³n base previamente guardada.

ğŸ§  Pregunta 13
Â¿CuÃ¡l es el propÃ³sito de los percentiles (p50, p95, p99) en benchmarking?

A. Determinar cobertura de lÃ­nea
B. Visualizar rutas de cÃ³digo no usadas
C. Identificar la distribuciÃ³n de tiempos de ejecuciÃ³n
D. Contar la cantidad de asserts por test

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Los percentiles muestran en quÃ© tiempo se ubican la mayorÃ­a de las ejecuciones, ayudando a detectar outliers o regresiones.

ğŸ§  Pregunta 14
Â¿QuÃ© mÃ©trica evalÃºa el nÃºmero de veces que un equipo despliega cÃ³digo en un periodo determinado?

A. Deployment Frequency
B. Change Failure Rate
C. Lead Time
D. Branch Coverage

âœ… Correcta: A
ğŸ§¾ ExplicaciÃ³n: La Deployment Frequency mide la agilidad del equipo para entregar software en producciÃ³n con frecuencia.

ğŸ§  Pregunta 15
Â¿CuÃ¡l es una ventaja de usar microbenchmarking en pruebas?

A. Reduce la cobertura de cÃ³digo
B. Aumenta el uso de memoria
C. EvalÃºa el rendimiento de funciones especÃ­ficas sin interferencias
D. Requiere menos lÃ­neas de test

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El microbenchmarking se enfoca en medir el rendimiento de funciones aisladas, evitando la contaminaciÃ³n de otros factores del entorno.

ğŸ§  Pregunta 16
Â¿QuÃ© plugin de pytest se utiliza para realizar benchmarking?

A. pytest-profile
B. pytest-cov
C. pytest-benchmark
D. pytest-metrics

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: pytest-benchmark es el plugin oficial para medir y comparar tiempos de ejecuciÃ³n de tests con estadÃ­sticas avanzadas.

ğŸ§  Pregunta 17
Â¿CuÃ¡l es el objetivo de la estrategia â€œno decrementarâ€ en cobertura?

A. Permitir que el coverage disminuya ligeramente
B. Asegurar que la cobertura de cÃ³digo nunca disminuya tras un merge
C. Evitar el uso de mocks y stubs
D. Reducir el tiempo de ejecuciÃ³n del pipeline

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Esta estrategia impide aprobar cambios que reduzcan la cobertura existente en la rama principal, manteniendo altos estÃ¡ndares de calidad.

ğŸ§  Pregunta 18
Â¿CuÃ¡l de los siguientes sistemas es una base de datos de series de tiempo Ãºtil para almacenar mÃ©tricas CI/CD?

A. MongoDB
B. Redis
C. InfluxDB
D. SQLite

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: InfluxDB estÃ¡ diseÃ±ado especÃ­ficamente para almacenar y consultar datos de series de tiempo, como los generados en benchmarking.

ğŸ§  Pregunta 19
Â¿QuÃ© herramienta se usa comÃºnmente junto con Prometheus para crear dashboards visuales?

A. JUnit
B. Coveralls
C. Grafana
D. Docker

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Grafana es una herramienta de visualizaciÃ³n de datos ampliamente utilizada para mostrar mÃ©tricas de Prometheus y otros orÃ­genes.

ğŸ§  Pregunta 20
Â¿CuÃ¡l es una prÃ¡ctica recomendada para reducir el ruido estadÃ­stico en los resultados de benchmarking?

A. Ejecutar los tests una sola vez
B. Desactivar las fixtures
C. Aumentar el nÃºmero de repeticiones por prueba
D. Ejecutar tests solo en horario nocturno

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Repetir los tests varias veces ayuda a obtener resultados mÃ¡s estables y confiables, reduciendo el impacto de variaciones aleatorias.

ğŸ§  Pregunta 21
Â¿QuÃ© mÃ©trica DORA refleja la capacidad del equipo para recuperarse de fallos?

A. Branch Coverage
B. MTTR
C. Test Duration
D. Deployment Frequency

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: MTTR (Mean Time to Recovery) mide el tiempo promedio que tarda un equipo en restaurar el servicio despuÃ©s de un incidente en producciÃ³n.

ğŸ§  Pregunta 22
Â¿Para quÃ© se usan los "Feature Flags" en un pipeline de despliegue?

A. Para reducir la duraciÃ³n del test
B. Para desactivar funcionalidades sin hacer un nuevo despliegue
C. Para aumentar la cobertura de sentencia
D. Para simular errores de producciÃ³n

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Los feature flags permiten controlar el comportamiento del sistema en tiempo real, activando o desactivando funcionalidades sin necesidad de redeploy.

ğŸ§  Pregunta 23
Â¿CuÃ¡l de estas opciones corresponde a un uso correcto de pytest para medir benchmark?

A. pytest --test-benchmark
B. pytest --cov=benchmark
C. pytest --benchmark-only
D. pytest --time-it

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La opciÃ³n --benchmark-only permite ejecutar exclusivamente los tests que contienen mediciones de rendimiento.

ğŸ§  Pregunta 24
Â¿Para quÃ© se utiliza la opciÃ³n --benchmark-fail-max-time-diff en pytest-benchmark?

A. Para calcular cobertura de ramas
B. Para detener pruebas lentas
C. Para bloquear un merge si los tests son mÃ¡s lentos que el benchmark base
D. Para generar reportes HTML

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Esta opciÃ³n establece un umbral mÃ¡ximo de diferencia de tiempo respecto al benchmark guardado, fallando el test si se excede.

ğŸ§  Pregunta 25
Â¿QuÃ© tipo de cobertura considera la cantidad de sentencias ejecutables, incluso si estÃ¡n en una misma lÃ­nea?

A. Cobertura de lÃ­nea
B. Cobertura de rama
C. Cobertura de funciÃ³n
D. Cobertura de sentencia

âœ… Correcta: D
ğŸ§¾ ExplicaciÃ³n: La cobertura de sentencia evalÃºa cada unidad ejecutable, lo que ofrece un anÃ¡lisis mÃ¡s detallado que simplemente contar lÃ­neas.

ğŸ§  Pregunta 26
Â¿QuÃ© acciÃ³n puede automatizarse en GitHub Actions para bloquear un merge si la cobertura baja del umbral esperado?

A. Crear un rollback
B. Enviar un ticket a Jira
C. Rechazar la Pull Request
D. Notificar al Product Owner

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Si la cobertura de pruebas desciende por debajo del umbral establecido (por ejemplo, 80â€¯%), GitHub Actions puede bloquear automÃ¡ticamente el merge.

ğŸ§  Pregunta 27
Â¿CuÃ¡l es un ejemplo de herramienta SaaS que permite monitorear y visualizar mÃ©tricas DORA?

A. Codecov
B. SonarQube
C. Datadog
D. pytest

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Datadog es una herramienta SaaS que permite combinar mÃ©tricas de CI/CD con trazas de aplicaciÃ³n para ofrecer una visiÃ³n unificada del rendimiento.

ğŸ§  Pregunta 28
Â¿CuÃ¡l es el componente mÃ¡s crÃ­tico para reducir el tiempo de diagnÃ³stico durante un incidente?

A. Tener mÃ¡s cobertura de lÃ­nea
B. Aumentar el nÃºmero de pull requests
C. Disponer de runbooks actualizados
D. Usar print() en producciÃ³n

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Los runbooks documentados permiten una rÃ¡pida identificaciÃ³n y soluciÃ³n de problemas recurrentes, reduciendo el MTTR.

ğŸ§  Pregunta 29
Â¿CuÃ¡l es una caracterÃ­stica clave de la mÃ©trica "Function Coverage"?

A. Valida la ejecuciÃ³n de condicionales
B. Cuenta sentencias por lÃ­nea
C. Verifica si cada funciÃ³n ha sido ejecutada
D. EvalÃºa performance del algoritmo

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La cobertura de funciÃ³n verifica que cada funciÃ³n o mÃ©todo haya sido llamado al menos una vez por la suite de pruebas.

ğŸ§  Pregunta 30
Â¿QuÃ© se busca evitar al configurar un "threshold global" de cobertura?

A. Que se instalen nuevas dependencias
B. Que se reduzca la cobertura general del cÃ³digo
C. Que se cree una nueva rama
D. Que se incrementen los errores de sintaxis

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: El threshold global define el mÃ­nimo aceptable de cobertura para todo el repositorio y evita que nuevos cambios reduzcan la calidad.

ğŸ§  Pregunta 31
Â¿CuÃ¡l es el objetivo de comparar benchmarks a lo largo del tiempo?

A. Aumentar la cobertura de ramas
B. Detectar regresiones de rendimiento
C. Borrar datos antiguos
D. Simplificar las pruebas

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Comparar benchmarks permite identificar si el cÃ³digo se ha vuelto mÃ¡s lento en nuevas versiones, lo que ayuda a prevenir degradaciones.

ğŸ§  Pregunta 32
Â¿En quÃ© casos se recomienda usar microbenchmarking?

A. Cuando el test incluye muchas funciones
B. Para medir el rendimiento aislado de una funciÃ³n crÃ­tica
C. En pruebas de UI
D. Para medir el uso de disco

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: El microbenchmarking se enfoca en analizar funciones especÃ­ficas con precisiÃ³n, sin interferencias del resto del entorno de prueba.

ğŸ§  Pregunta 33
Â¿QuÃ© mÃ©trica se usa para representar la proporciÃ³n de bifurcaciones de cÃ³digo cubiertas?

A. Line coverage
B. Function coverage
C. Branch coverage
D. Time coverage

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La cobertura de ramas mide si se han ejecutado todas las bifurcaciones de cada decisiÃ³n lÃ³gica (if, else, bucles, etc.).

ğŸ§  Pregunta 34
Â¿CuÃ¡l de los siguientes formatos permite exportar datos desde pytest-benchmark?

A. CSV Ãºnicamente
B. YAML
C. JSON
D. Markdown

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: pytest-benchmark permite exportar sus resultados en formato JSON, ideal para integraciÃ³n con otras herramientas y visualizaciones.

ğŸ§  Pregunta 35
Â¿QuÃ© beneficio aporta parametrizar pruebas de rendimiento en pytest?

A. Disminuye el uso de RAM
B. Permite evaluar cÃ³mo escala el algoritmo con diferentes tamaÃ±os de entrada
C. Reduce el tiempo de test
D. Elimina la necesidad de fixtures

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: La parametrizaciÃ³n permite probar el rendimiento con mÃºltiples tamaÃ±os de entrada, lo cual es Ãºtil para evaluar la escalabilidad.

ğŸ§  Pregunta 36
Â¿CuÃ¡l es una recomendaciÃ³n clave al ejecutar benchmarks para asegurar resultados confiables?

A. Ejecutarlos en horario laboral
B. Mezclar pruebas funcionales y de rendimiento
C. Aislar el entorno de ejecuciÃ³n
D. Activar procesos en segundo plano

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Ejecutar los benchmarks en un entorno controlado y aislado minimiza la variabilidad y hace los resultados mÃ¡s precisos.

ğŸ§  Pregunta 37
Â¿CuÃ¡l es una forma de monitorear la evoluciÃ³n del MTTR a lo largo del tiempo?

A. Usar print() para imprimir logs
B. Crear tickets manualmente
C. Visualizar mÃ©tricas en Grafana con series temporales
D. Evaluar el nÃºmero de ramas activas

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Grafana permite visualizar datos histÃ³ricos como el MTTR usando dashboards interactivos con base en series temporales.

ğŸ§  Pregunta 38
Â¿QuÃ© ventaja tiene la integraciÃ³n de mÃ©tricas con sistemas como Prometheus?

A. Elimina pruebas redundantes
B. Optimiza cÃ³digo duplicado
C. Permite realizar alertas automÃ¡ticas sobre umbrales
D. Desactiva PRs con conflictos

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Prometheus permite definir reglas de alerta basadas en mÃ©tricas y dispararlas cuando superan los lÃ­mites definidos.

ğŸ§  Pregunta 39
Â¿CuÃ¡l es el propÃ³sito de definir â€œPolicies y SLOs para el pipelineâ€?

A. Limitar el nÃºmero de desarrolladores activos
B. Crear ramas automÃ¡ticas por cada commit
C. Establecer objetivos medibles de rendimiento y calidad
D. Forzar merges en horarios especÃ­ficos

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Los SLOs (Service Level Objectives) ayudan a establecer expectativas sobre la calidad y velocidad del pipeline, y se usan como indicadores de salud.

ğŸ§  Pregunta 40
Â¿QuÃ© tÃ©cnica permite desactivar un feature en caso de alta tasa de fallos?

A. Refactor automÃ¡tico
B. Feature flag dinÃ¡mico
C. Hotfix manual
D. Restart de servicios

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Las feature flags dinÃ¡micas permiten desactivar automÃ¡ticamente funcionalidades problemÃ¡ticas ante mÃ©tricas crÃ­ticas como fallos o latencia alta.

ğŸ§  Pregunta 41
Â¿CuÃ¡l de estas herramientas permite emitir mÃ©tricas directamente desde el pipeline?

A. Slack
B. pytest
C. python -m http.server
D. GitHub Pages

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Se puede usar python -m http.server para exponer archivos como metrics.prom y permitir que Prometheus los scrapee.

ğŸ§  Pregunta 42
Â¿QuÃ© mÃ©trica se recomienda analizar con heatmaps o histogramas en Grafana?

A. NÃºmero de ramas
B. DuraciÃ³n de los tests
C. Nombre del desarrollador
D. Nombre del archivo test

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Las heatmaps o histogramas son Ãºtiles para visualizar la distribuciÃ³n del tiempo de ejecuciÃ³n de pruebas a lo largo de diferentes contextos.

ğŸ§  Pregunta 43
Â¿QuÃ© tipo de cobertura es mÃ¡s detallada que la cobertura de lÃ­nea?

A. Cobertura de test
B. Cobertura de funciÃ³n
C. Cobertura de sentencia
D. Cobertura de mÃ©trica

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La cobertura de sentencia considera mÃºltiples sentencias en una misma lÃ­nea, haciendo su anÃ¡lisis mÃ¡s granular que la cobertura de lÃ­nea.

ğŸ§  Pregunta 44
Â¿QuÃ© acciÃ³n puede ejecutarse al superar el umbral de MTTR?

A. Ejecutar comandos desde Slack (ChatOps)
B. Ocultar mÃ©tricas de producciÃ³n
C. Reiniciar la base de datos
D. Eliminar tests lentos

âœ… Correcta: A
ğŸ§¾ ExplicaciÃ³n: Con ChatOps, los equipos pueden reaccionar rÃ¡pidamente a mÃ©tricas crÃ­ticas ejecutando scripts o comandos directamente desde Slack o Teams.

ğŸ§  Pregunta 45
Â¿QuÃ© informaciÃ³n clave debe tener una mÃ©trica para ser Ãºtil en anÃ¡lisis multidimensional?

A. Valor absoluto
B. DescripciÃ³n en inglÃ©s
C. Etiquetas (labels) como branch, job_name o runner
D. El nombre del autor del commit

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Las etiquetas permiten filtrar y correlacionar mÃ©tricas segÃºn mÃºltiples dimensiones del pipeline y del entorno de ejecuciÃ³n.

ğŸ§  Pregunta 46
Â¿QuÃ© formato se recomienda usar al emitir mÃ©tricas para Prometheus?

A. Markdown
B. XML
C. Prometheus exposition format
D. YAML

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Prometheus utiliza un formato especÃ­fico de exposiciÃ³n de mÃ©tricas que puede ser scrapeado fÃ¡cilmente desde archivos .prom.

ğŸ§  Pregunta 47
Â¿CuÃ¡l es una herramienta de visualizaciÃ³n que permite generar anotaciones sobre eventos relevantes?

A. pytest
B. New Relic
C. Coveralls
D. Grafana

âœ… Correcta: D
ğŸ§¾ ExplicaciÃ³n: Grafana permite crear anotaciones verticales que indican eventos significativos como releases o cambios de infraestructura.

ğŸ§  Pregunta 48
Â¿QuÃ© herramienta permite detectar duplicaciÃ³n de cÃ³digo y complejidad junto con mÃ©tricas de cobertura?

A. InfluxDB
B. pytest-benchmark
C. SonarQube
D. Prometheus

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: SonarQube analiza la cobertura de pruebas y tambiÃ©n la complejidad, duplicaciÃ³n de cÃ³digo, y otros aspectos de calidad estÃ¡tica del software.

ğŸ§  Pregunta 49
Â¿QuÃ© tipo de test se recomienda ejecutar progresivamente con distintos tamaÃ±os de entrada para evaluar escalabilidad?

A. Test de UI
B. Test de humo
C. Test parametrizado
D. Test de rollback

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Los tests parametrizados permiten evaluar el rendimiento de un componente bajo diferentes volÃºmenes de carga, midiendo asÃ­ su escalabilidad.

ğŸ§  Pregunta 50
Â¿QuÃ© indicador podrÃ­a disparar una alerta automÃ¡tica si supera el 20 % en la Ãºltima semana?

A. Lead Time
B. MTTR
C. Change Failure Rate
D. Deployment Frequency

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El Change Failure Rate elevado indica inestabilidad en los despliegues y puede ser usado como condiciÃ³n para rechazar futuros despliegues automÃ¡ticos.
