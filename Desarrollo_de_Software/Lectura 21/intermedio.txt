ğŸ§  Pregunta 1
Â¿CuÃ¡l es el objetivo principal de medir la cobertura de pruebas en un contexto DevOps?

A. Optimizar el tiempo de ejecuciÃ³n de las pruebas.
B. Asegurar que todo el cÃ³digo sea revisado por mÃºltiples desarrolladores.
C. Cuantificar la proporciÃ³n del cÃ³digo que ha sido ejecutada por pruebas automatizadas para mantener la calidad.
D. Reducir el nÃºmero total de pruebas automatizadas.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La cobertura de pruebas busca medir quÃ© tanto del cÃ³digo se valida automÃ¡ticamente, siendo crucial en DevOps para prevenir la degradaciÃ³n de la calidad en los merges.

ğŸ§  Pregunta 2
Â¿QuÃ© diferencia fundamental existe entre la cobertura de lÃ­nea y la cobertura de rama?

A. La cobertura de lÃ­nea considera todas las sentencias, mientras que la de rama solo las condicionales.
B. La cobertura de rama se enfoca en las lÃ­neas ejecutadas, mientras que la de lÃ­nea analiza las bifurcaciones.
C. La cobertura de lÃ­nea mide el porcentaje de lÃ­neas ejecutadas, mientras que la de rama evalÃºa los caminos de decisiÃ³n (verdadero/falso) en el cÃ³digo.
D. No existe una diferencia significativa entre ambas mÃ©tricas.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La cobertura de lÃ­nea indica quÃ© lÃ­neas se ejecutaron, pero la de rama va mÃ¡s allÃ¡, asegurando que se prueben todos los posibles resultados de las estructuras de control (if/else, bucles, etc.).

ğŸ§  Pregunta 3
En un pipeline CI/CD, Â¿cuÃ¡l es el paso inmediatamente posterior a la ejecuciÃ³n de la suite de pruebas con la opciÃ³n de cobertura activada?

A. Despliegue a producciÃ³n.
B. GeneraciÃ³n del informe de cobertura en formatos como HTML o XML.
C. ValidaciÃ³n de la complejidad ciclomÃ¡tica del cÃ³digo.
D. NotificaciÃ³n al equipo de desarrollo sobre los resultados de las pruebas.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: DespuÃ©s de ejecutar las pruebas con la herramienta de cobertura, el siguiente paso lÃ³gico es generar un informe que detalle quÃ© partes del cÃ³digo fueron cubiertas.

ğŸ§  Pregunta 4
Â¿QuÃ© representa la estrategia de "no decrementar" en la definiciÃ³n de umbrales de cobertura?

A. Permitir que la cobertura disminuya ligeramente en nuevas funcionalidades.
B. Bloquear merges que resulten en una disminuciÃ³n de la cobertura de pruebas existente.
C. Aumentar gradualmente los umbrales de cobertura con cada nuevo despliegue.
D. Ignorar las disminuciones de cobertura en mÃ³dulos no crÃ­ticos.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: La estrategia de "no decrementar" busca mantener o mejorar la calidad del cÃ³digo base al evitar que la cobertura de pruebas se reduzca con la introducciÃ³n de nuevos cambios.

ğŸ§  Pregunta 5
Â¿CuÃ¡l de las siguientes herramientas se menciona como capaz de analizar la cobertura de pruebas junto con otros indicadores de calidad del cÃ³digo como la complejidad ciclomÃ¡tica?

A. Codecov.
B. Coveralls.
C. SonarQube.
D. pytest-benchmark.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: SonarQube es una plataforma que integra el anÃ¡lisis de cobertura con otras mÃ©tricas de calidad del cÃ³digo, proporcionando una visiÃ³n mÃ¡s completa de la salud del software.

ğŸ§  Pregunta 6
Â¿CuÃ¡l es el principal propÃ³sito del plugin pytest-benchmark en el ecosistema de pruebas de Python?

A. Generar informes de cobertura de cÃ³digo detallados.
B. Medir y comparar el tiempo de ejecuciÃ³n de las pruebas a lo largo del tiempo.
C. Facilitar la creaciÃ³n de pruebas de integraciÃ³n complejas.
D. Automatizar la ejecuciÃ³n de pruebas en diferentes entornos.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: pytest-benchmark se enfoca en el rendimiento de las pruebas, permitiendo a los desarrolladores identificar regresiones de tiempo y optimizar la suite de pruebas.

ğŸ§  Pregunta 7
Â¿QuÃ© informaciÃ³n valiosa proporcionan los percentiles (p50, p95, p99) en los resultados de pytest-benchmark?

A. El nÃºmero total de pruebas ejecutadas.
B. El tiempo promedio de ejecuciÃ³n de toda la suite de pruebas.
C. El valor debajo del cual cae un cierto porcentaje de ejecuciones, ayudando a identificar valores atÃ­picos (outliers).
D. La diferencia entre la ejecuciÃ³n mÃ¡s rÃ¡pida y la mÃ¡s lenta.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Los percentiles ofrecen una visiÃ³n de la distribuciÃ³n de los tiempos de ejecuciÃ³n, siendo Ãºtiles para detectar pruebas que ocasionalmente tardan mucho mÃ¡s de lo normal.

ğŸ§  Pregunta 8
Â¿QuÃ© utilidad tiene el parÃ¡metro --benchmark-fail-max-time-diff en pytest-benchmark dentro de un pipeline CI?

A. Permite guardar los resultados de las pruebas de rendimiento en un archivo especÃ­fico.
B. Compara los resultados de la ejecuciÃ³n actual con una lÃ­nea base guardada previamente.
C. Detiene el pipeline si alguna prueba excede un porcentaje definido de lentitud en comparaciÃ³n con la lÃ­nea base.
D. Define el nÃºmero mÃ­nimo de repeticiones para cada prueba de rendimiento.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Este parÃ¡metro es crucial para la calidad, ya que evita que se introduzcan cambios que degraden significativamente el rendimiento de las pruebas sin ser detectados.

ğŸ§  Pregunta 9
Â¿CuÃ¡l de las siguientes NO es una de las cuatro mÃ©tricas DORA (DevOps Research and Assessment) utilizadas para medir el rendimiento de la entrega de software?

A. Lead Time for Changes (Tiempo de entrega de cambios).
B. Deployment Frequency (Frecuencia de despliegue).
C. Code Churn Rate (Tasa de rotaciÃ³n de cÃ³digo).
D. Change Failure Rate (Tasa de fallos en cambios).

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Code Churn Rate no es una de las cuatro mÃ©tricas DORA principales, las cuales se centran en la velocidad y la estabilidad de la entrega.

ğŸ§  Pregunta 10
Â¿QuÃ© mide el "Lead Time for Changes" dentro de las mÃ©tricas DORA?

A. El tiempo que tarda un desarrollador en escribir el cÃ³digo para una nueva funcionalidad.
B. El tiempo transcurrido desde que se detecta un fallo en producciÃ³n hasta que se resuelve.
C. El tiempo entre el commit de un cambio y su disponibilidad en producciÃ³n para los usuarios finales.
D. La frecuencia con la que se realizan despliegues a los diferentes entornos (desarrollo, staging, producciÃ³n).

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El Lead Time for Changes es un indicador clave de la agilidad del equipo y la eficiencia del pipeline de entrega.

ğŸ§  Pregunta 11
Una alta "Deployment Frequency" generalmente indica:

A. Una mayor probabilidad de fallos en producciÃ³n debido a la falta de pruebas exhaustivas.
B. Un pipeline de entrega robusto y confiable que permite entregar valor de forma iterativa.
C. Que el equipo de desarrollo se enfoca en entregar grandes lotes de funcionalidades de forma menos frecuente.
D. Una menor necesidad de automatizaciÃ³n de pruebas debido a la rapidez de los despliegues.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Despliegues frecuentes suelen ser posibles gracias a una buena automatizaciÃ³n y confianza en el proceso de entrega.

ğŸ§  Pregunta 12
Â¿QuÃ© significa una baja "Change Failure Rate" segÃºn las mÃ©tricas DORA?

A. Que los despliegues son muy frecuentes, lo que minimiza el impacto de los fallos.
B. Que el equipo prioriza la velocidad de entrega por encima de la estabilidad.
C. Que los despliegues son estables y las prÃ¡cticas de testing e integraciÃ³n son efectivas.
D. Que se realizan pocos cambios al cÃ³digo, lo que reduce la probabilidad de errores.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Una baja tasa de fallos en los cambios es un buen indicador de la calidad del proceso de desarrollo y despliegue.

ğŸ§  Pregunta 13
Â¿CuÃ¡l es el objetivo principal de medir el "Mean Time to Recovery" (MTTR)?

A. Evaluar la frecuencia con la que el equipo realiza despliegues a producciÃ³n.
B. Medir la eficiencia del equipo en la detecciÃ³n y resoluciÃ³n de incidentes en producciÃ³n.
C. Cuantificar el tiempo que tardan los desarrolladores en escribir y probar nuevas funcionalidades.
D. Determinar el porcentaje de despliegues que resultan en fallos o rollbacks.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: El MTTR se centra en la resiliencia del sistema y la capacidad del equipo para restaurar el servicio rÃ¡pidamente despuÃ©s de una interrupciÃ³n.

ğŸ§  Pregunta 14
Â¿QuÃ© componente del "Lead Time for Changes" se enfoca en la ejecuciÃ³n de pruebas unitarias y el empaquetado de artefactos?

A. Tiempo de aprobaciÃ³n.
B. Tiempo de despliegue.
C. Tiempo de build.
D. Tiempo de integraciÃ³n.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El tiempo de build abarca las etapas iniciales del pipeline donde se compila y se prueban las unidades mÃ¡s pequeÃ±as del cÃ³digo.

ğŸ§  Pregunta 15
Â¿QuÃ© tipo de pruebas se mencionan como importantes para reducir la "Change Failure Rate" ademÃ¡s de las pruebas unitarias?

A. Pruebas de rendimiento y pruebas de usabilidad.
B. Pruebas de estrÃ©s y pruebas de seguridad.
C. Smoke tests y pruebas de contrato (contract testing) para APIs externas.
D. Pruebas exploratorias y pruebas A/B.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Las smoke tests verifican la funcionalidad bÃ¡sica despuÃ©s del despliegue, mientras que las pruebas de contrato aseguran la compatibilidad con servicios externos.

ğŸ§  Pregunta 16
Â¿QuÃ© se debe hacer para transformar los registros de ejecuciÃ³n de un servidor CI/CD en mÃ©tricas accionables?

A. Analizar manualmente los logs de texto plano.
B. Ignorar los datos de ejecuciÃ³n y centrarse en el cÃ³digo fuente.
C. Emitir mÃ©tricas en formatos estÃ¡ndar como Prometheus text exposition format o JSON.
D. Almacenar los logs sin procesar en una base de datos.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La emisiÃ³n estructurada facilita la recolecciÃ³n y el anÃ¡lisis automatizado de las mÃ©tricas por herramientas como Prometheus.

ğŸ§  Pregunta 17
En el contexto de la captura de mÃ©tricas desde el pipeline CI/CD, Â¿quÃ© propÃ³sito tienen los "hooks" o "post steps"?

A. Ejecutar tareas al inicio de cada job del pipeline.
B. Definir las dependencias entre diferentes etapas del pipeline.
C. Calcular y exportar mÃ©tricas despuÃ©s de la finalizaciÃ³n de un job.
D. Visualizar las mÃ©tricas en un dashboard en tiempo real.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Los "post steps" permiten realizar acciones como el cÃ¡lculo de duraciones y la exportaciÃ³n de mÃ©tricas una vez que la tarea principal del job ha concluido.

ğŸ§  Pregunta 18
Â¿CÃ³mo se integra el plugin pytest-benchmark con un pipeline CI para la captura de mÃ©tricas de rendimiento?

A. Ejecutando las pruebas sin ninguna opciÃ³n adicional y analizando los logs.
B. Utilizando la opciÃ³n --benchmark-json para exportar los resultados en formato JSON, que luego puede ser transformado.
C. Enviando directamente los resultados a un sistema de series de tiempo como Prometheus.
D. Mostrando los resultados Ãºnicamente en la salida estÃ¡ndar del pipeline.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: La exportaciÃ³n a JSON permite un procesamiento posterior para adaptar los datos al formato requerido por los sistemas de monitorizaciÃ³n.

ğŸ§  Pregunta 19
Â¿CuÃ¡l es la principal diferencia entre el modelo de recolecciÃ³n de mÃ©tricas de Prometheus y el de InfluxDB?

A. Prometheus utiliza un modelo push, donde los agentes envÃ­an las mÃ©tricas, mientras que InfluxDB usa un modelo pull.
B. InfluxDB se basa en archivos de texto plano, mientras que Prometheus utiliza una base de datos optimizada para series de tiempo.
C. Prometheus utiliza un modelo pull, donde el servidor scrapea los endpoints de los expositores de mÃ©tricas, mientras que InfluxDB usa un modelo push.
D. No hay una diferencia significativa en sus modelos de recolecciÃ³n.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Esta diferencia en el modelo de recolecciÃ³n influye en cÃ³mo se instrumentan los sistemas para exponer y almacenar las mÃ©tricas.

ğŸ§  Pregunta 20
Â¿Por quÃ© es importante el etiquetado (labels) en los sistemas de series de tiempo como Prometheus?

A. Para reducir el tamaÃ±o de la base de datos de mÃ©tricas.
B. Para definir la retenciÃ³n de las mÃ©tricas.
C. Para facilitar el anÃ¡lisis multidimensional y el filtrado de las mÃ©tricas por diferentes contextos.
D. Para mejorar el rendimiento de la recolecciÃ³n de mÃ©tricas.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Las etiquetas aÃ±aden contexto a las mÃ©tricas, permitiendo segmentar y analizar los datos de manera mÃ¡s efectiva.

ğŸ§  Pregunta 21
Â¿QuÃ© tipo de panel en Grafana es mÃ¡s adecuado para mostrar la tendencia del tiempo promedio desde el commit hasta el despliegue en producciÃ³n?

A. Un panel de tipo "stat".
B. Un panel de tipo "bar gauge".
C. Un grÃ¡fico de lÃ­nea.
D. Una tabla.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Un grÃ¡fico de lÃ­nea es ideal para visualizar la evoluciÃ³n de una mÃ©trica a lo largo del tiempo, como el Lead Time.

ğŸ§  Pregunta 22
Â¿QuÃ© utilidad tienen las "variables" en los dashboards de Grafana?

A. Permiten crear paneles estÃ¡ticos con valores predefinidos.
B. Facilitan la ediciÃ³n masiva de mÃºltiples paneles simultÃ¡neamente.
C. Permiten cambiar rÃ¡pidamente el contexto de los datos visualizados sin necesidad de editar los paneles.
D. Mejoran el rendimiento de la carga de los dashboards.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Las variables hacen que los dashboards sean mÃ¡s interactivos y adaptables a diferentes anÃ¡lisis.

ğŸ§  Pregunta 23
Â¿CuÃ¡l es el propÃ³sito principal de configurar alertas en un sistema de monitorizaciÃ³n como Prometheus Alertmanager?

A. Generar informes periÃ³dicos sobre el estado del pipeline.
B. Detectar tempranamente deterioros en el pipeline y mantener la confiabilidad del proceso de entrega.
C. Visualizar las mÃ©tricas histÃ³ricas del rendimiento del pipeline.
D. Automatizar la creaciÃ³n de dashboards en Grafana.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Las alertas son fundamentales para la detecciÃ³n proactiva de problemas que puedan afectar la velocidad o la estabilidad de la entrega.

ğŸ§  Pregunta 24
Â¿QuÃ© tipo de reglas se definen en Prometheus para generar alertas basadas en el comportamiento de las mÃ©tricas?

A. Reglas de grabaciÃ³n (recording rules).
B. Reglas de alerta (alerting rules).
C. Reglas de consulta (query rules).
D. Reglas de visualizaciÃ³n (visualization rules).

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Las "alerting rules" especifican las condiciones bajo las cuales se deben disparar las notificaciones de alerta.

ğŸ§  Pregunta 25
Â¿QuÃ© son los "Service Level Objectives (SLOs)" aplicados al pipeline de entrega de software?

A. MÃ©tricas detalladas del rendimiento de cada etapa del pipeline.
B. Objetivos de rendimiento definidos para el propio proceso de entrega, como el tiempo de entrega o la frecuencia de despliegue.
C. Acuerdos con los usuarios finales sobre la disponibilidad del software desplegado.
D. LÃ­mites mÃ¡ximos aceptables para las mÃ©tricas de rendimiento del pipeline.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Los SLOs para el pipeline permiten medir y gestionar la eficiencia y la calidad del proceso de desarrollo y despliegue como un servicio interno.

ğŸ§  Pregunta 26
Â¿CÃ³mo se puede implementar el "gatekeeping" en pull requests utilizando mÃ©tricas de benchmarking en GitHub Actions?

A. Revisando manualmente los resultados de los benchmarks despuÃ©s de cada pull request.
B. Configurando un job que compare los benchmarks con una lÃ­nea base y bloquee el merge si se exceden los umbrales definidos.
C. Utilizando herramientas externas para analizar los benchmarks despuÃ©s de que el cÃ³digo se ha mergeado.
D. Mostrando los resultados de los benchmarks solo como una nota informativa en el pull request.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: La automatizaciÃ³n de la comparaciÃ³n de benchmarks en el pipeline de pull requests previene la introducciÃ³n de cÃ³digo que degrade el rendimiento.

ğŸ§  Pregunta 27
Â¿QuÃ© mecanismo se puede utilizar en pipelines CI/CD para reaccionar automÃ¡ticamente ante una alta tasa de fallos en producciÃ³n (Change Failure Rate)?

A. Aumentar la frecuencia de los despliegues para diluir el impacto de los fallos.
B. Desactivar automÃ¡ticamente nuevas funcionalidades mediante feature flags.
C. Detener todas las actividades de desarrollo hasta que se resuelvan los fallos.
D. Reducir el nÃºmero de pruebas automatizadas para acelerar los despliegues.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Los feature flags ofrecen una forma rÃ¡pida de mitigar el impacto de problemas introducidos por nuevos despliegues sin necesidad de un rollback completo.

ğŸ§  Pregunta 28
Â¿QuÃ© tipo de informaciÃ³n sensible se debe tener en cuenta al trabajar con mÃ©tricas de pipelines?

A. El nÃºmero total de lÃ­neas de cÃ³digo modificadas.
B. La frecuencia con la que los desarrolladores hacen commit.
C. Nombres de branches privados, identificadores de tickets y variables de entorno.
D. El tiempo de ejecuciÃ³n de las pruebas unitarias.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Es crucial filtrar y controlar el acceso a la informaciÃ³n que podrÃ­a comprometer la seguridad o la privacidad.

ğŸ§  Pregunta 29
Â¿CuÃ¡l es la importancia de la automatizaciÃ³n de respuestas basadas en mÃ©tricas en un entorno DevOps maduro?

A. Reducir la necesidad de monitorizaciÃ³n manual de los dashboards.
B. Permitir que el sistema reaccione automÃ¡ticamente ante problemas sin intervenciÃ³n humana inmediata.
C. Generar informes mÃ¡s detallados sobre el rendimiento del pipeline.
D. Facilitar la comunicaciÃ³n entre los diferentes equipos involucrados en el ciclo de vida del software.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: La automatizaciÃ³n de respuestas aumenta la eficiencia y la resiliencia del proceso de entrega al abordar problemas de forma proactiva.

ğŸ§  Pregunta 30
Â¿QuÃ© beneficio aporta la correlaciÃ³n y el anÃ¡lisis multidimensional de las mÃ©tricas de benchmarking y DORA?

A. Simplifica la visualizaciÃ³n de los datos en dashboards mÃ¡s concisos.
B. Permite entender cÃ³mo interactÃºan las diferentes mÃ©tricas y obtener una visiÃ³n integral del proceso de entrega.
C. Reduce la cantidad de datos que necesitan ser almacenados y analizados.
D. Facilita la definiciÃ³n de umbrales de alerta mÃ¡s precisos.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Comprender las relaciones entre las mÃ©tricas proporciona un contexto mÃ¡s rico para la toma de decisiones y la identificaciÃ³n de Ã¡reas de mejora.

ğŸ§  Pregunta 31
Â¿QuÃ© ventaja ofrece la emisiÃ³n estructurada de mÃ©tricas en el pipeline CI/CD en comparaciÃ³n con el anÃ¡lisis de logs de texto plano?

A. Permite una interpretaciÃ³n mÃ¡s subjetiva de los datos.
B. Facilita la recolecciÃ³n y el anÃ¡lisis automatizado por herramientas de monitorizaciÃ³n.
C. Reduce la cantidad de informaciÃ³n generada por el pipeline.
D. Elimina la necesidad de herramientas de visualizaciÃ³n como Grafana.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: La estructura facilita que las mÃ¡quinas interpreten y procesen los datos de manera eficiente.

ğŸ§  Pregunta 32
Â¿CÃ³mo contribuyen los "etiquetados" o "labels" a la utilidad de las mÃ©tricas en sistemas como Prometheus?

A. Definen el tipo de grÃ¡fico que se utilizarÃ¡ para visualizar la mÃ©trica.
B. Determinan la frecuencia con la que se recolecta la mÃ©trica.
C. Permiten segmentar, filtrar y analizar las mÃ©tricas por diferentes dimensiones o contextos.
D. Aseguran que todas las mÃ©tricas tengan un nombre Ãºnico.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Los labels son esenciales para entender el contexto de cada punto de datos.

ğŸ§  Pregunta 33
En un dashboard de Grafana dedicado a mÃ©tricas de CI/CD, Â¿quÃ© tipo de panel serÃ­a mÃ¡s adecuado para mostrar la cantidad de despliegues exitosos por dÃ­a durante la Ãºltima semana?

A. Un grÃ¡fico de lÃ­nea.
B. Un panel de tipo "gauge".
C. Un panel de tipo "stat" o un grÃ¡fico de barras.
D. Un histograma.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Un contador simple o un grÃ¡fico de barras son ideales para mostrar cantidades discretas a lo largo del tiempo.

ğŸ§  Pregunta 34
Â¿CuÃ¡l es la funciÃ³n principal de las "anotaciones" en los dashboards de Grafana?

A. Mostrar valores agregados de las mÃ©tricas.
B. Permitir a los usuarios interactuar con los grÃ¡ficos.
C. Marcar eventos significativos para ayudar a correlacionar cambios con las mÃ©tricas.
D. Definir umbrales de alerta visuales en los grÃ¡ficos.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Las anotaciones proporcionan contexto narrativo a los datos visualizados.

ğŸ§  Pregunta 35
Â¿QuÃ© diferencia existe entre las "reglas de grabaciÃ³n" y las "reglas de alerta" en Prometheus?

A. Las reglas de grabaciÃ³n definen cÃ³mo se almacenan las mÃ©tricas, mientras que las de alerta definen cuÃ¡ndo notificar.
B. Las reglas de grabaciÃ³n pre-calculan y almacenan nuevas series de tiempo basadas en consultas, mientras que las de alerta definen las condiciones para disparar notificaciones.
C. Las reglas de grabaciÃ³n se utilizan para visualizar datos en Grafana, mientras que las de alerta se usan en Alertmanager.
D. No hay una diferencia funcional significativa entre ambas.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Las reglas de grabaciÃ³n optimizan las consultas, mientras que las de alerta automatizan las notificaciones.

ğŸ§  Pregunta 36
Â¿CuÃ¡l es el propÃ³sito de definir "silencers temporales" en la configuraciÃ³n de Alertmanager?

A. Reducir el volumen de alertas enviadas.
B. Evitar el envÃ­o de alertas durante periodos de mantenimiento planificado.
C. Priorizar las alertas mÃ¡s crÃ­ticas.
D. Rerutar las alertas a diferentes equipos segÃºn su tipo.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Los silencers ayudan a evitar ruido innecesario durante periodos conocidos de inactividad o intervenciÃ³n.

ğŸ§  Pregunta 37
Â¿CÃ³mo se pueden utilizar las mÃ©tricas de comparaciÃ³n de benchmarks para configurar alertas sobre regresiones de rendimiento?

A. Alertando si el tiempo de ejecuciÃ³n absoluto de una prueba excede un umbral fijo.
B. Alertando si el tiempo de ejecuciÃ³n de una prueba disminuye significativamente.
C. Alertando si el incremento reciente en el tiempo de ejecuciÃ³n de una prueba es significativamente mayor que su promedio histÃ³rico.
D. Alertando si el nÃºmero total de pruebas de rendimiento disminuye.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Comparar el rendimiento actual con el histÃ³rico ayuda a detectar degradaciones sutiles.

ğŸ§  Pregunta 38
Â¿CuÃ¡l es el beneficio de definir Service Level Objectives (SLOs) para el pipeline de entrega?

A. Garantizar que el software desplegado cumpla con los requisitos del usuario final.
B. Medir y gestionar la eficiencia y la calidad del proceso de desarrollo y despliegue como un servicio interno.
C. Reducir los costos asociados con la infraestructura del pipeline.
D. Aumentar la velocidad de los despliegues individuales.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Los SLOs proporcionan objetivos claros para el rendimiento del propio proceso de entrega.

ğŸ§  Pregunta 39
En el contexto de GitHub Actions, Â¿cÃ³mo se puede utilizar un "check" basado en mÃ©tricas de benchmarking para controlar los merges de pull requests?

A. Mostrando una advertencia si los benchmarks se degradan, pero permitiendo el merge.
B. Bloqueando el merge si los benchmarks exceden un umbral definido, asegurando que no se introduzca cÃ³digo con rendimiento degradado.
C. Registrando los resultados de los benchmarks solo despuÃ©s de que el cÃ³digo ha sido mergeado.
D. Permitiendo que los desarrolladores ignoren los fallos de los benchmarks si consideran que son insignificantes.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Los checks automatizados actÃºan como una puerta de calidad para el cÃ³digo.

ğŸ§  Pregunta 40
Â¿CÃ³mo pueden los "feature flags dinÃ¡micos" contribuir a la automatizaciÃ³n de respuestas ante problemas detectados por las mÃ©tricas de producciÃ³n?

A. Permitiendo a los desarrolladores modificar el cÃ³digo en producciÃ³n directamente.
B. Facilitando la reversiÃ³n de cambios mediante rollbacks automÃ¡ticos del despliegue completo.
C. Permitiendo la activaciÃ³n o desactivaciÃ³n de funcionalidades sin necesidad de redeployar, en respuesta a mÃ©tricas como la tasa de fallos.
D. Redirigiendo el trÃ¡fico de usuarios a versiones anteriores del software automÃ¡ticamente.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Los feature flags ofrecen una forma granular y rÃ¡pida de mitigar problemas.

ğŸ§  Pregunta 41
Â¿QuÃ© tipo de herramientas se pueden integrar con los sistemas de alerta para automatizar la creaciÃ³n de tickets de seguimiento ante incidentes detectados por las mÃ©tricas?

A. Herramientas de visualizaciÃ³n de dashboards como Grafana.
B. Sistemas de gestiÃ³n de proyectos y seguimiento de incidencias como Jira o Azure Boards.
C. Sistemas de control de versiones como Git.
D. Herramientas de comunicaciÃ³n en equipo como Slack o Microsoft Teams.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: La integraciÃ³n con sistemas de ticketing automatiza el flujo de trabajo de respuesta a incidentes.

ğŸ§  Pregunta 42
Â¿CuÃ¡l es la principal preocupaciÃ³n al manejar mÃ©tricas de pipelines que contienen informaciÃ³n sensible?

A. El impacto en el rendimiento de los sistemas de almacenamiento de mÃ©tricas.
B. El cumplimiento de las polÃ­ticas de retenciÃ³n de datos.
C. La exposiciÃ³n no autorizada de informaciÃ³n confidencial.
D. La dificultad para analizar grandes volÃºmenes de datos.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La seguridad y la privacidad de la informaciÃ³n sensible deben ser una prioridad.

ğŸ§  Pregunta 43
Â¿QuÃ© prÃ¡ctica se menciona para mitigar los riesgos de exponer informaciÃ³n sensible en las mÃ©tricas de pipelines?

A. Cifrar toda la informaciÃ³n transmitida a los sistemas de monitorizaciÃ³n.
B. Auditar regularmente los logs del pipeline en busca de informaciÃ³n sensible.
C. Filtrar o evitar la exposiciÃ³n de etiquetas que contengan datos confidenciales.
D. Almacenar las mÃ©tricas sensibles en un sistema separado con acceso restringido.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La prevenciÃ³n en la exposiciÃ³n es una estrategia clave.

ğŸ§  Pregunta 44
Â¿CÃ³mo puede la automatizaciÃ³n de la creaciÃ³n de documentaciÃ³n basada en mÃ©tricas beneficiar a los equipos de desarrollo y operaciones?

A. Reduciendo la necesidad de escribir documentaciÃ³n manual.
B. Proporcionando informes actualizados y basados en datos reales sobre el rendimiento del pipeline.
C. Mejorando la comunicaciÃ³n con los usuarios finales sobre el estado del software.
D. Automatizando el proceso de despliegue a producciÃ³n.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: La documentaciÃ³n automatizada asegura que la informaciÃ³n sea precisa y estÃ© disponible para la revisiÃ³n y la toma de decisiones.

ğŸ§  Pregunta 45
Â¿QuÃ© tipo de anÃ¡lisis se facilita al correlacionar las mÃ©tricas de Lead Time con las mÃ©tricas de benchmarking de las pruebas?

A. Identificar quÃ© desarrolladores contribuyen mÃ¡s al tiempo de entrega.
B. Determinar si la lentitud en el pipeline estÃ¡ relacionada con la duraciÃ³n de la suite de pruebas.
C. Predecir la frecuencia futura de los despliegues.
D. Evaluar el impacto de los cambios de cÃ³digo en la tasa de fallos en producciÃ³n.

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Esta correlaciÃ³n ayuda a optimizar el pipeline identificando cuellos de botella.

ğŸ§  Pregunta 46
Â¿QuÃ© posible consecuencia puede tener una frecuencia de despliegue muy alta si no se cuenta con una automatizaciÃ³n robusta de pruebas end-to-end?

A. Un aumento en el Lead Time for Changes.
B. Una disminuciÃ³n en el Mean Time to Recovery.
C. Un incremento en la Change Failure Rate.
D. Una reducciÃ³n en la complejidad del cÃ³digo desplegado.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Despliegues frecuentes sin pruebas adecuadas aumentan el riesgo de introducir fallos.

ğŸ§  Pregunta 47
Â¿CÃ³mo puede un equipo con prÃ¡cticas de "trunk-based development" beneficiarse en tÃ©rminos del Mean Time to Recovery (MTTR)?

A. Al tener ramas de larga duraciÃ³n, se pueden aislar mejor los fallos.
B. Al tener merges mÃ¡s complejos, se fuerza una revisiÃ³n mÃ¡s exhaustiva del cÃ³digo.
C. Al reducir la complejidad de los merges, se facilita la aplicaciÃ³n rÃ¡pida de hotfixes.
D. Al eliminar las ramas de desarrollo, se evitan los conflictos de merge.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Un flujo de trabajo simplificado facilita la correcciÃ³n rÃ¡pida de problemas.

ğŸ§  Pregunta 48
Â¿QuÃ© rol juega la monitorizaciÃ³n proactiva y las alertas en la reducciÃ³n del Mean Time to Recovery (MTTR)?

A. Permiten identificar la causa raÃ­z de los incidentes mÃ¡s rÃ¡pidamente.
B. Reducen la necesidad de realizar rollbacks ante fallos.
C. Aceleran el proceso de desarrollo de los hotfixes.
D. Facilitan la detecciÃ³n temprana de problemas antes de que impacten significativamente al usuario.

âœ… Correcta: D
ğŸ§¾ ExplicaciÃ³n: La detecciÃ³n temprana es crucial para una recuperaciÃ³n mÃ¡s rÃ¡pida.

ğŸ§  Pregunta 49
Â¿QuÃ© tipo de anÃ¡lisis permite la combinaciÃ³n de mÃ©tricas de infraestructura, logs y procesos de despliegue en una plataforma unificada como New Relic o Datadog?

A. Un anÃ¡lisis aislado del rendimiento de cada componente.
B. Una visiÃ³n fragmentada del ciclo de vida del software.
C. Una perspectiva holÃ­stica que facilita la correlaciÃ³n de problemas en diferentes capas.
D. Un anÃ¡lisis centrado Ãºnicamente en las mÃ©tricas de negocio.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La unificaciÃ³n de datos proporciona un contexto mÃ¡s completo para el diagnÃ³stico y la resoluciÃ³n de problemas.

ğŸ§  Pregunta 50
Â¿CuÃ¡l es el objetivo final de integrar las mÃ©tricas de rendimiento en el ciclo de vida del software?

A. Generar informes mÃ¡s detallados para la direcciÃ³n.
B. Reducir la carga de trabajo de los equipos de desarrollo y operaciones.
C. Permitir a los equipos monitorizar tendencias, detectar anomalÃ­as y activar acciones automÃ¡ticas para mejorar continuamente la velocidad y la estabilidad de la entrega.
D. Justificar la inversiÃ³n en herramientas de monitorizaciÃ³n y automatizaciÃ³n.

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El objetivo es mejorar continuamente el proceso de entrega basÃ¡ndose en datos objetivos.