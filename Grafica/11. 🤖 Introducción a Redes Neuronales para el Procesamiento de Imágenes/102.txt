ğŸ§  Pregunta 11

Brainscore es un benchmark que evalÃºa:

A. La velocidad de inferencia de una CNN en GPU
B. El parecido entre las activaciones de una CNN y las respuestas neuronales de primates
C. La cantidad de datos necesaria para entrenar una red
D. El consumo energÃ©tico de modelos grandes

âœ… Correcta: B

ğŸ§¾ ExplicaciÃ³n: Compara correlaciones estadÃ­sticamente entre capas de red y registros neuronales.

ğŸ§  Pregunta 12

SegÃºn Hardt & Recht, la razÃ³n pragmÃ¡tica principal por la que el deep learning domina hoy es:

A. Explica perfectamente los mecanismos de la inteligencia humana
B. Funciona mejor en muchos problemas prÃ¡cticos y cuenta con abundante software libre y datos
C. Requiere muy poco poder computacional
D. No necesita ajustar hiperparÃ¡metros

âœ… Correcta: B

ğŸ§¾ ExplicaciÃ³n: Rendimiento superior y herramientas abiertas impulsan su adopciÃ³n industrial y acadÃ©mica.

ğŸ§  Pregunta 13

En el ejemplo mÃ­nimo de Keras, la capa MaxPool2D aporta principalmente:

A. Aprendizaje de bordes diagonales
B. ReducciÃ³n de resoluciÃ³n y cierta invariancia a traslaciones locales
C. PropagaciÃ³n del gradiente sin saturaciÃ³n
D. Aumento del nÃºmero de parÃ¡metros

âœ… Correcta: B

ğŸ§¾ ExplicaciÃ³n: Agrupa regiones vecinas, reduce dimensionalidad y hace que pequeÃ±as traslaciones no cambien la activaciÃ³n.

ğŸ§  Pregunta 14

El primer â€œinviernoâ€ de la IA se asocia a:

A. Falta de datos disponibles en los aÃ±os 80
B. Expectativas no cumplidas tras la limitaciÃ³n del perceptrÃ³n evidenciada por Minsky y Papert
C. La prohibiciÃ³n gubernamental de investigar aprendizaje automÃ¡tico
D. La crisis financiera global de 2008

âœ… Correcta: B

ğŸ§¾ ExplicaciÃ³n: El pesimismo tras el libro de 1969 redujo el financiamiento y el interÃ©s por redes neuronales.

ğŸ§  Pregunta 15

Â¿QuÃ© componente de una CNN imita la idea biolÃ³gica de â€œdetectores de caracterÃ­sticas localesâ€ descubierta por Hubel & Wiesel?

A. Las conexiones totalmente densas
B. Los filtros de convoluciÃ³n que comparten pesos a lo largo de la imagen
C. El algoritmo de optimizaciÃ³n Adam
D. El uso de funciones de activaciÃ³n sigmoide

âœ… Correcta: B

ğŸ§¾ ExplicaciÃ³n: Un filtro responde a un patrÃ³n local especÃ­fico, similar a neuronas que detectan bordes en cierta orientaciÃ³n.

ğŸ§  Pregunta 16

En el ejercicio de Keras, la funciÃ³n softmax en la capa final se encarga de:

A. Calcular la pÃ©rdida de entrenamiento
B. Convertir la salida en probabilidades normalizadas para cada clase de dÃ­gito
C. Pre-procesar las imÃ¡genes de entrada
D. Evitar el sobreajuste mediante regularizaciÃ³n

âœ… Correcta: B

ğŸ§¾ ExplicaciÃ³n: softmax transforma los logits en un vector cuya suma es uno, facilitando la clasificaciÃ³n.

ğŸ§  Pregunta 17

La jerarquÃ­a de caracterÃ­sticas aprendida por una CNN se describe comÃºnmente como:

A. Texto â†’ voz â†’ imagen
B. Detalles finos primero, despuÃ©s bordes, por Ãºltimo espacio de color
C. Bordes simples en capas bajas, partes de objetos en intermedias y conceptos completos en altas
D. PÃ­xeles individuales en todas las capas

âœ… Correcta: C

ğŸ§¾ ExplicaciÃ³n: Cada nivel combina elementos del anterior, formando representaciones mÃ¡s abstractas.

ğŸ§  Pregunta 18

El tÃ©rmino â€œcampo receptivo crecienteâ€ significa que al avanzar en la red:

A. Disminuye la complejidad de los filtros
B. Aumenta el nÃºmero de parÃ¡metros en cada neurona
C. Cada neurona integra informaciÃ³n de una regiÃ³n mÃ¡s grande de la imagen original
D. Se reduce el tamaÃ±o del vector de salida

âœ… Correcta: C

ğŸ§¾ ExplicaciÃ³n: Combinaciones sucesivas de convoluciÃ³n y pooling expanden la zona influyente sobre la activaciÃ³n de una neurona.

ğŸ§  Pregunta 19

El Ã©xito de AlexNet se debiÃ³ en parte al uso de GPU porque:

A. Permitieron entrenar redes profundas en tiempos manejables aprovechando paralelismo masivo
B. Aumentaron la precisiÃ³n aritmÃ©tica de los cÃ¡lculos
C. Evitaron la necesidad de back-propagation
D. Incrementaron automÃ¡ticamente la cantidad de datos disponibles

âœ… Correcta: A

ğŸ§¾ ExplicaciÃ³n: Las GPUs aceleraron las operaciones de convoluciÃ³n, haciendo viable el entrenamiento de millones de parÃ¡metros.

ğŸ§  Pregunta 20

La trayectoria histÃ³rica resumida (McCulloch-Pitts â†’ AlexNet â†’ Brainscore) muestra que el avance clave ha sido:

A. Sustituir todas las funciones de activaciÃ³n por lineales
B. Integrar ideas biolÃ³gicas, algoritmos de optimizaciÃ³n y potencia computacional creciente
C. Eliminar completamente la necesidad de datos etiquetados
D. Volver a redes de una sola capa

âœ… Correcta: B

ğŸ§¾ ExplicaciÃ³n: Cada etapa combinÃ³ inspiraciÃ³n neurobiolÃ³gica, mejoras matemÃ¡ticas (back-prop, ReLU) y hardware/datos masivos para superar la anterior.

