ğŸ§  Pregunta 51
Â¿QuÃ© representa el sÃ­mbolo ğ‘š en la fÃ³rmula de la funciÃ³n de coste?

A. El nÃºmero de caracterÃ­sticas
B. El valor predicho
C. El nÃºmero de ejemplos de entrenamiento
D. El learning rate

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: ğ‘š representa la cantidad total de ejemplos que hay en el conjunto de datos de entrenamiento.

ğŸ§  Pregunta 52
Â¿Por quÃ© es necesario entrenar un modelo de regresiÃ³n lineal?

A. Para elegir la mejor funciÃ³n de activaciÃ³n
B. Para encontrar los valores Ã³ptimos de los parÃ¡metros
C. Para limpiar los datos
D. Para clasificar ejemplos en grupos

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: El entrenamiento ajusta los parÃ¡metros (Î¸) para que la funciÃ³n hipÃ³tesis se ajuste lo mejor posible a los datos.

ğŸ§  Pregunta 53
Â¿QuÃ© se entiende por funciÃ³n hipÃ³tesis multivariable?

A. FunciÃ³n con una salida categÃ³rica
B. FunciÃ³n que usa varias etiquetas
C. FunciÃ³n con mÃºltiples caracterÃ­sticas de entrada
D. FunciÃ³n con mÃºltiples datasets

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La funciÃ³n hipÃ³tesis multivariable tiene mÃ¡s de una variable de entrada y, por lo tanto, mÃºltiples parÃ¡metros.

ğŸ§  Pregunta 54
Â¿QuÃ© indica una pendiente (Î¸â‚) igual a cero?

A. Que hay un error en los datos
B. Que la salida no varÃ­a con la entrada
C. Que el modelo estÃ¡ sobreajustado
D. Que el bias es negativo

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Una pendiente cero implica que el valor de salida no cambia al modificar la entrada; es una recta horizontal.

ğŸ§  Pregunta 55
Â¿CuÃ¡l es el objetivo principal del algoritmo de gradiente descendente?

A. Aumentar el error del modelo
B. Encontrar el mÃ¡ximo de la funciÃ³n de coste
C. Minimizar la funciÃ³n de coste ajustando parÃ¡metros
D. Evitar el uso de funciones derivadas

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El gradiente descendente ajusta los parÃ¡metros del modelo para que el error (funciÃ³n de coste) sea el mÃ­nimo posible.

ğŸ§  Pregunta 56
Â¿QuÃ© se requiere para calcular la funciÃ³n de coste?

A. Solo los valores de entrada
B. Solo las predicciones
C. Las predicciones y los valores reales
D. La tasa de aprendizaje

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La funciÃ³n de coste compara las predicciones del modelo con los valores reales del conjunto de datos.

ğŸ§  Pregunta 57
Â¿QuÃ© hace la derivada en el algoritmo de gradiente descendente?

A. Indica la posiciÃ³n exacta del mÃ­nimo
B. Sirve para clasificar ejemplos
C. Determina la direcciÃ³n del ajuste de los parÃ¡metros
D. Estima la regularizaciÃ³n

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La derivada de la funciÃ³n de coste indica cÃ³mo ajustar los parÃ¡metros para reducir el error.

ğŸ§  Pregunta 58
Â¿QuÃ© significa que una funciÃ³n tenga una pendiente negativa?

A. La salida disminuye al aumentar la entrada
B. El error cuadrÃ¡tico es positivo
C. La salida aumenta con la entrada
D. El modelo es no supervisado

âœ… Correcta: A
ğŸ§¾ ExplicaciÃ³n: Una pendiente negativa implica que al aumentar X, la predicciÃ³n Y disminuye.

ğŸ§  Pregunta 59
Â¿QuÃ© representa el sÃ­mbolo ğ›¼ (alpha) en el gradiente descendente?

A. NÃºmero de variables
B. Tasa de aprendizaje
C. NÃºmero de muestras
D. Valor del bias

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: ğ›¼ es el learning rate, que controla quÃ© tan grandes son los pasos que da el algoritmo al ajustar los parÃ¡metros.

ğŸ§  Pregunta 60
Â¿QuÃ© sucede si el learning rate es muy alto?

A. El modelo converge mÃ¡s rÃ¡pido y de forma precisa
B. El modelo puede saltarse el mÃ­nimo global
C. El modelo se entrena sin errores
D. El modelo reduce automÃ¡ticamente los parÃ¡metros

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Un valor muy alto puede hacer que el modelo no se estabilice y se salte el punto Ã³ptimo.

