ğŸ§  Pregunta 61
Â¿CuÃ¡l es la forma general de la funciÃ³n hipÃ³tesis univariable?

A. 
ğ‘¦
^
=
ğœƒ
0
+
ğœƒ
1
ğ‘¥
y
^
â€‹
 =Î¸ 
0
â€‹
 +Î¸ 
1
â€‹
 x
B. 
ğ‘¦
^
=
ğœƒ
0
ğ‘¥
2
+
ğœƒ
1
ğ‘¥
y
^
â€‹
 =Î¸ 
0
â€‹
 x 
2
 +Î¸ 
1
â€‹
 x
C. 
ğ‘¦
^
=
ğ‘¥
+
ğ‘¦
y
^
â€‹
 =x+y
D. 
ğ‘¦
^
=
ğœƒ
0
ğ‘¥
+
ğœƒ
1
ğ‘¥
y
^
â€‹
 =Î¸ 
0
â€‹
 x+Î¸ 
1
â€‹
 x

âœ… Correcta: A
ğŸ§¾ ExplicaciÃ³n: En regresiÃ³n lineal con una sola variable, la funciÃ³n hipÃ³tesis es una lÃ­nea recta con bias y pendiente.

ğŸ§  Pregunta 62
Â¿QuÃ© mide la derivada parcial de la funciÃ³n de coste respecto a un parÃ¡metro?

A. La media de los errores
B. La velocidad de aprendizaje
C. El cambio del error con respecto a ese parÃ¡metro
D. La cantidad de caracterÃ­sticas

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: La derivada parcial muestra cuÃ¡nto cambia el error si se ajusta ligeramente un parÃ¡metro.

ğŸ§  Pregunta 63
Â¿QuÃ© determina la magnitud del ajuste de parÃ¡metros en gradiente descendente?

A. La cantidad de caracterÃ­sticas
B. El nÃºmero de ejemplos
C. El valor de la derivada y la tasa de aprendizaje
D. El tipo de funciÃ³n de coste

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El tamaÃ±o del ajuste depende de la derivada (pendiente) y del learning rate (ğ›¼).

ğŸ§  Pregunta 64
Â¿QuÃ© representa el valor Å· (y sombrero) en el modelo?

A. Valor real observado
B. Salida predicha por el modelo
C. Error cuadrÃ¡tico
D. IntersecciÃ³n con el eje X

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Å· es la predicciÃ³n que hace el modelo para una entrada X dada.

ğŸ§  Pregunta 65
Â¿CuÃ¡l de los siguientes pasos es parte del ciclo de entrenamiento?

A. ConstrucciÃ³n de un Ã¡rbol de decisiÃ³n
B. NormalizaciÃ³n de etiquetas
C. InicializaciÃ³n, cÃ¡lculo del error, optimizaciÃ³n
D. ClasificaciÃ³n de datos

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El ciclo de entrenamiento en regresiÃ³n lineal incluye iniciar con parÃ¡metros, calcular el error y optimizar iterativamente.

ğŸ§  Pregunta 66
Â¿Por quÃ© se usa el cuadrado del error en la funciÃ³n MSE?

A. Para minimizar el tiempo de ejecuciÃ³n
B. Para igualar valores positivos y negativos
C. Para resaltar errores grandes y eliminar negativos
D. Para clasificar los datos

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Elevar al cuadrado los errores evita que se cancelen entre sÃ­ y penaliza los errores grandes.

ğŸ§  Pregunta 67
Â¿QuÃ© papel cumple el tÃ©rmino Î¸â‚€ en una funciÃ³n multivariable?

A. Multiplica todas las caracterÃ­sticas
B. Se utiliza para eliminar el bias
C. Es el tÃ©rmino independiente (bias)
D. Solo se usa en clasificaciÃ³n

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: En la hipÃ³tesis multivariable, Î¸â‚€ es el tÃ©rmino bias que se suma al resto de productos.

ğŸ§  Pregunta 68
Â¿QuÃ© ocurre si todos los errores individuales son cero?

A. El modelo no sirve
B. La funciÃ³n de coste es infinita
C. La funciÃ³n de coste es cero
D. El modelo necesita mÃ¡s entrenamiento

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Si las predicciones coinciden con los valores reales, el error cuadrÃ¡tico y la funciÃ³n de coste son cero.

ğŸ§  Pregunta 69
Â¿CuÃ¡ndo se detiene el algoritmo de gradiente descendente?

A. Cuando se alcanza una derivada mÃ¡xima
B. Cuando la funciÃ³n de coste aumenta
C. Cuando los ajustes son insignificantes
D. Cuando se usan todos los datos

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El gradiente descendente se detiene cuando las actualizaciones son tan pequeÃ±as que no vale la pena continuar.

ğŸ§  Pregunta 70
Â¿QuÃ© se necesita calcular antes de actualizar los parÃ¡metros?

A. La precisiÃ³n
B. El tamaÃ±o del dataset
C. El gradiente de la funciÃ³n de coste
D. La matriz de confusiÃ³n

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Para actualizar los parÃ¡metros, se requiere calcular el gradiente (la derivada) de la funciÃ³n de coste.

