ğŸ§  Pregunta 71
Â¿QuÃ© representa el tÃ©rmino "learning rate"?

A. El nÃºmero de pasos que toma el modelo
B. La intensidad del entrenamiento
C. El tamaÃ±o del paso en cada iteraciÃ³n
D. El nÃºmero de caracterÃ­sticas

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El learning rate (ğ›¼) controla el tamaÃ±o del paso que da el algoritmo al ajustar los parÃ¡metros.

ğŸ§  Pregunta 72
Â¿QuÃ© ocurre si el modelo de regresiÃ³n lineal tiene muchos parÃ¡metros?

A. Siempre mejora el rendimiento
B. PodrÃ­a sobreajustarse a los datos
C. Se convierte en una red neuronal
D. La funciÃ³n de coste no se puede calcular

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Demasiados parÃ¡metros pueden hacer que el modelo se ajuste demasiado al entrenamiento, perdiendo capacidad de generalizaciÃ³n.

ğŸ§  Pregunta 73
Â¿QuÃ© se obtiene como resultado del entrenamiento?

A. Un conjunto nuevo de datos
B. Un conjunto de funciones objetivo
C. Valores Ã³ptimos para Î¸â‚€, Î¸â‚, ...
D. El valor mÃ¡s bajo posible de X

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: El entrenamiento busca determinar los mejores valores para los parÃ¡metros que definen la funciÃ³n hipÃ³tesis.

ğŸ§  Pregunta 74
Â¿QuÃ© representa una lÃ­nea con pendiente muy pronunciada?

A. Poca relaciÃ³n entre X y Y
B. RelaciÃ³n inversa
C. Alta sensibilidad de Y ante cambios en X
D. Modelo no supervisado

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Una pendiente pronunciada indica que un pequeÃ±o cambio en X genera un cambio grande en Y.

ğŸ§  Pregunta 75
Â¿QuÃ© condiciÃ³n debe cumplir la funciÃ³n de coste para asegurar que el gradiente descendente encuentre el mejor resultado?

A. Ser constante
B. Ser cÃ³ncava
C. Ser convexa
D. Tener mÃºltiples picos

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Una funciÃ³n convexa tiene un Ãºnico mÃ­nimo global, lo que garantiza que el gradiente descendente lo encontrarÃ¡.

ğŸ§  Pregunta 76
Â¿QuÃ© representa la suma ponderada en la funciÃ³n hipÃ³tesis?

A. La multiplicaciÃ³n de parÃ¡metros por una constante
B. La predicciÃ³n mÃ¡s alta posible
C. Cada caracterÃ­stica multiplicada por su peso (Î¸)
D. El error cuadrÃ¡tico medio

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: En la suma ponderada, cada caracterÃ­stica se multiplica por su parÃ¡metro correspondiente y se suman todos los resultados.

ğŸ§  Pregunta 77
Â¿CuÃ¡l es una ventaja del gradiente descendente?

A. Elimina la necesidad de una funciÃ³n de coste
B. Encuentra el valor mÃ­nimo de una funciÃ³n compleja
C. Permite entrenar modelos sin datos
D. Se usa solo en modelos no supervisados

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: El gradiente descendente puede minimizar funciones de coste complejas y encontrar el mejor ajuste del modelo.

ğŸ§  Pregunta 78
Â¿QuÃ© significa que un modelo tenga alta varianza?

A. Se ajusta muy poco a los datos
B. Tiene pocos parÃ¡metros
C. Se ajusta demasiado a los datos de entrenamiento
D. Tiene mÃºltiples funciones de coste

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Un modelo con alta varianza se ajusta demasiado al conjunto de entrenamiento y puede fallar con datos nuevos.

ğŸ§  Pregunta 79
Â¿QuÃ© se busca en el proceso de ajuste de parÃ¡metros?

A. Eliminar variables
B. Minimizar el tamaÃ±o del dataset
C. Encontrar el valor mÃ­nimo de la funciÃ³n de coste
D. Maximizar la tasa de aprendizaje

âœ… Correcta: C
ğŸ§¾ ExplicaciÃ³n: Ajustar los parÃ¡metros significa modificar Î¸â‚€, Î¸â‚, â€¦ hasta minimizar el error del modelo.

ğŸ§  Pregunta 80
Â¿Con quÃ© frecuencia se actualizan los parÃ¡metros en el gradiente descendente?

A. Solo al final del entrenamiento
B. En cada iteraciÃ³n
C. Cada vez que cambia la funciÃ³n de coste
D. Cuando el error es cero

âœ… Correcta: B
ğŸ§¾ ExplicaciÃ³n: Los parÃ¡metros se actualizan iterativamente en cada paso del gradiente descendente para ir mejorando el modelo.

